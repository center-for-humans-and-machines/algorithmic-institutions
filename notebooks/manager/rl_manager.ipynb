{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b173f42",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "artificial_humans = \"../../data/artificial_humans/04_3_2_model/model/architecture_node+edge+rnn.pt\"\n",
    "artificial_humans_valid = \"../../data/artificial_humans/02_4_valid/model/rnn_True.pt\"\n",
    "artificial_humans_model = \"graph\"\n",
    "data_dir = \"../../data/manager_v3/dev/\"\n",
    "manager_args = {\n",
    "    \"opt_args\": {\"lr\": 0.003},\n",
    "    \"gamma\": 1.0,\n",
    "    \"eps\": 0.2,\n",
    "    \"target_update_freq\": 20,\n",
    "    \"model_args\": {\n",
    "        \"hidden_size\": 5,\n",
    "        \"add_rnn\": False,\n",
    "        \"add_edge_model\": False,\n",
    "        \"add_global_model\": False,\n",
    "        \"x_encoding\": [\n",
    "            {\"name\": \"contributions\", \"n_levels\": 21, \"encoding\": \"numeric\"},\n",
    "            {\"name\":\"is_first\", \"etype\": 'bool' }\n",
    "        ],\n",
    "        \"b_encoding\": [{\"name\": \"round_number\", \"n_levels\": 16, \"encoding\": \"onehot\"}],\n",
    "    },\n",
    "}\n",
    "replay_memory_args = {\"n_episodes\": 100}\n",
    "n_update_steps = 50\n",
    "eval_period = 2\n",
    "env_args = {\n",
    "    \"n_agents\": 4,\n",
    "    \"n_contributions\": 21,\n",
    "    \"n_punishments\": 31,\n",
    "    \"n_rounds\": 16,\n",
    "    \"batch_size\": 1000,\n",
    "}\n",
    "device = \"cpu\"\n",
    "job_id = \"dev\"\n",
    "labels = {}\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c92424",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpib/brinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch as th\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from itertools import count\n",
    "\n",
    "from aimanager.manager.memory import Memory\n",
    "from aimanager.manager.environment import ArtificialHumanEnv\n",
    "from aimanager.artificial_humans import AH_MODELS\n",
    "from aimanager.manager.manager import ArtificalManager\n",
    "from aimanager.utils.utils import make_dir\n",
    "from aimanager.utils.array_to_df import add_labels\n",
    "\n",
    "metrics_dir = os.path.join(data_dir, 'metrics')\n",
    "model_dir = os.path.join(data_dir, 'model')\n",
    "make_dir(metrics_dir)\n",
    "make_dir(model_dir)\n",
    "\n",
    "\n",
    "th.random.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9400cf5",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "rec_keys = [\n",
    "    'punishment', 'contribution', 'common_good', 'contributor_payoff', 'manager_payoff']\n",
    "\n",
    "def run_batch(manager, env, replay_mem=None, on_policy=True, update_step=None):\n",
    "\n",
    "    state = env.reset()\n",
    "    metric_list = []\n",
    "    for round_number in count():\n",
    "        encoded = manager.encode(state, edge_index=env.batch_edge_index)\n",
    "\n",
    "        # Get q values from controller\n",
    "        q_values = manager.get_q(encoded, first=round_number == 0)\n",
    "    \n",
    "        if on_policy:\n",
    "            action = q_values.argmax(-1)\n",
    "        else:\n",
    "            # Sample a action\n",
    "            action = manager.eps_greedy(q_values=q_values)\n",
    "\n",
    "        state = env.punish(action)\n",
    "        \n",
    "        metrics = {k: state[k].to(th.float).mean().item() for k in rec_keys}\n",
    "\n",
    "        # pass actions to environment and advance by one step\n",
    "        state, reward, done = env.step()\n",
    "        if replay_mem is not None:\n",
    "            replay_mem.add(\n",
    "                episode_step=round_number, action=action, reward=reward, \n",
    "                **{k:v for k, v in encoded.items() if k not in ['edge_index', 'batch']})\n",
    "\n",
    "        metrics['next_reward'] = reward.mean().item()\n",
    "        metrics['q_min'] = q_values.min().item()\n",
    "        metrics['q_max'] = q_values.max().item()\n",
    "        metrics['q_mean'] = q_values.mean().item()\n",
    "        metrics['round_number'] = round_number\n",
    "        metrics['sampling'] = 'greedy' if on_policy else 'eps-greedy'\n",
    "        metrics['update_step'] = update_step\n",
    "        metric_list.append(metrics)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    return metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02d293a0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded in comparison",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m metrics_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m update_step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_update_steps):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m# replay_mem.start_batch(env.groups)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m# here we sample one batch of episodes and add them to the replay buffer\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     off_policy_metrics \u001b[39m=\u001b[39m run_batch(manager, env, replay_mem, on_policy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, update_step\u001b[39m=\u001b[39;49mupdate_step)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     replay_mem\u001b[39m.\u001b[39mnext_episode(update_step)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# allow manager to update itself\u001b[39;00m\n",
      "\u001b[1;32m/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb Cell 4\u001b[0m in \u001b[0;36mrun_batch\u001b[0;34m(manager, env, replay_mem, on_policy, update_step)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_batch\u001b[39m(manager, env, replay_mem\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, on_policy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, update_step\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mreset()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     metric_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m round_number \u001b[39min\u001b[39;00m count():\n",
      "File \u001b[0;32m/mnt/beegfs/home/brinkmann/repros/algorithmic-institutions/aimanager/manager/environment.py:201\u001b[0m, in \u001b[0;36mArtificialHumanEnv.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_state()\n\u001b[0;32m--> 201\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_contribution()\n\u001b[1;32m    202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\n",
      "File \u001b[0;32m/mnt/beegfs/home/brinkmann/repros/algorithmic-institutions/aimanager/manager/environment.py:171\u001b[0m, in \u001b[0;36mArtificialHumanEnv.update_contribution\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_contribution\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    163\u001b[0m     \u001b[39m# artificial humans\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39martifical_humans\u001b[39m.\u001b[39mencode(\n\u001b[1;32m    165\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate,\n\u001b[1;32m    166\u001b[0m         mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice,\n\u001b[1;32m    170\u001b[0m     )\n\u001b[0;32m--> 171\u001b[0m     contribution \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49martifical_humans\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m    172\u001b[0m         encoded, reset_rnn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mround_number[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m] \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m\n\u001b[1;32m    173\u001b[0m     )[\u001b[39m0\u001b[39m]\n\u001b[1;32m    175\u001b[0m     \u001b[39m# artificial humans valid\u001b[39;00m\n\u001b[1;32m    176\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39martifical_humans_valid \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/beegfs/home/brinkmann/repros/algorithmic-institutions/aimanager/generic/graph.py:344\u001b[0m, in \u001b[0;36mGraphNetwork.predict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_autoreg(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/beegfs/home/brinkmann/repros/algorithmic-institutions/aimanager/generic/graph.py:344\u001b[0m, in \u001b[0;36mGraphNetwork.predict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_autoreg(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "    \u001b[0;31m[... skipping similar frames: GraphNetwork.predict at line 344 (2967 times)]\u001b[0m\n",
      "File \u001b[0;32m/mnt/beegfs/home/brinkmann/repros/algorithmic-institutions/aimanager/generic/graph.py:344\u001b[0m, in \u001b[0;36mGraphNetwork.predict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_autoreg(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded in comparison"
     ]
    }
   ],
   "source": [
    "device = th.device(device)\n",
    "cpu = th.device('cpu')\n",
    "\n",
    "artificial_humans = AH_MODELS[artificial_humans_model].load(artificial_humans, device=device).to(device)\n",
    "artificial_humans_valid = AH_MODELS[artificial_humans_model].load(artificial_humans_valid, device=device).to(device)\n",
    "\n",
    "env = ArtificialHumanEnv(\n",
    "    artifical_humans=artificial_humans, artifical_humans_valid=artificial_humans_valid, device=device, **env_args)\n",
    "\n",
    "manager = ArtificalManager(\n",
    "    n_contributions=env.n_contributions, n_punishments=env.n_punishments, \n",
    "    default_values=artificial_humans.default_values, device=device, **manager_args)\n",
    "\n",
    "replay_mem = Memory(\n",
    "    n_episode_steps=env.n_rounds, device=cpu, **replay_memory_args)\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "for update_step in range(n_update_steps):\n",
    "    # replay_mem.start_batch(env.groups)\n",
    "\n",
    "    # here we sample one batch of episodes and add them to the replay buffer\n",
    "    off_policy_metrics = run_batch(manager, env, replay_mem, on_policy=False, update_step=update_step)\n",
    "\n",
    "    replay_mem.next_episode(update_step)\n",
    "    \n",
    "    # allow manager to update itself\n",
    "    sample = replay_mem.get_random(device=device)\n",
    "\n",
    "    if sample is not None:\n",
    "        loss = manager.update(update_step, **sample, batch=env.batch, edge_index=env.batch_edge_index)\n",
    "    \n",
    "    if (update_step % eval_period) == 0:\n",
    "        metrics_list.extend([{**m, 'loss': l.item()} for m, l in zip(off_policy_metrics, loss)])\n",
    "        metrics_list.extend(\n",
    "            run_batch(manager, env, replay_mem=None, on_policy=True, update_step=update_step))\n",
    "\n",
    "model_file = os.path.join(model_dir, f'{job_id}.pt')\n",
    "\n",
    "manager.save(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee6155e",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The following 'id_vars' are not present in the DataFrame: ['round_number', 'sampling', 'update_step']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m value_vars \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mpunishments\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcontributions\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcommon_good\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcontributor_payoff\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mmanager_payoff\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnext_reward\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mq_min\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mq_max\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mq_mean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_records(metrics_list)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mmelt(id_vars\u001b[39m=\u001b[39;49mid_vars, value_vars\u001b[39m=\u001b[39;49mvalue_vars, var_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmetric\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m df \u001b[39m=\u001b[39m add_labels(df, {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mlabels, \u001b[39m'\u001b[39m\u001b[39mjob_id\u001b[39m\u001b[39m'\u001b[39m: job_id})\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m df\u001b[39m.\u001b[39mto_parquet(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(metrics_dir, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mjob_id\u001b[39m}\u001b[39;00m\u001b[39m.parquet\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/pandas/core/frame.py:8434\u001b[0m, in \u001b[0;36mDataFrame.melt\u001b[0;34m(self, id_vars, value_vars, var_name, value_name, col_level, ignore_index)\u001b[0m\n\u001b[1;32m   8423\u001b[0m \u001b[39m@Appender\u001b[39m(_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mmelt\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcaller\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mdf.melt(\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mother\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmelt\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m   8424\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmelt\u001b[39m(\n\u001b[1;32m   8425\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8431\u001b[0m     ignore_index: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   8432\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m-> 8434\u001b[0m     \u001b[39mreturn\u001b[39;00m melt(\n\u001b[1;32m   8435\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   8436\u001b[0m         id_vars\u001b[39m=\u001b[39;49mid_vars,\n\u001b[1;32m   8437\u001b[0m         value_vars\u001b[39m=\u001b[39;49mvalue_vars,\n\u001b[1;32m   8438\u001b[0m         var_name\u001b[39m=\u001b[39;49mvar_name,\n\u001b[1;32m   8439\u001b[0m         value_name\u001b[39m=\u001b[39;49mvalue_name,\n\u001b[1;32m   8440\u001b[0m         col_level\u001b[39m=\u001b[39;49mcol_level,\n\u001b[1;32m   8441\u001b[0m         ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m   8442\u001b[0m     )\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/pandas/core/reshape/melt.py:77\u001b[0m, in \u001b[0;36mmelt\u001b[0;34m(frame, id_vars, value_vars, var_name, value_name, col_level, ignore_index)\u001b[0m\n\u001b[1;32m     75\u001b[0m         missing \u001b[39m=\u001b[39m Index(com\u001b[39m.\u001b[39mflatten(id_vars))\u001b[39m.\u001b[39mdifference(cols)\n\u001b[1;32m     76\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m missing\u001b[39m.\u001b[39mempty:\n\u001b[0;32m---> 77\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m     78\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mThe following \u001b[39m\u001b[39m'\u001b[39m\u001b[39mid_vars\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are not present \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39min the DataFrame: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(missing)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m             )\n\u001b[1;32m     81\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     id_vars \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyError\u001b[0m: \"The following 'id_vars' are not present in the DataFrame: ['round_number', 'sampling', 'update_step']\""
     ]
    }
   ],
   "source": [
    "id_vars = ['round_number', 'sampling', 'update_step']\n",
    "value_vars = ['punishments', 'contributions', 'common_good', 'contributor_payoff',\n",
    "       'manager_payoff', 'next_reward', 'q_min', 'q_max', 'q_mean', 'loss']\n",
    "\n",
    "df = pd.DataFrame.from_records(metrics_list)\n",
    "\n",
    "df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='metric')\n",
    "\n",
    "df = add_labels(df, {**labels, 'job_id': job_id})\n",
    "\n",
    "df.to_parquet(os.path.join(metrics_dir, f'{job_id}.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "input_path": "notebooks/manager/rl_manager_v3.ipynb",
   "output_path": "notebooks/manager/rl_manager_v3.ipynb",
   "parameters": {
    "artificial_humans": "../../artifacts/artificial_humans/01_rnn_edge_features/model/rnn_True__edge_True__global_features_False.pt",
    "artificial_humans_model": "graph",
    "artificial_humans_valid": "../../artifacts/artificial_humans/02_valid/model/rnn_True.pt",
    "data_dir": "../../data/manager_v3/dev/",
    "device": "cpu",
    "env_args": {
     "batch_size": 1000,
     "n_agents": 4,
     "n_contributions": 21,
     "n_punishments": 31,
     "n_rounds": 16
    },
    "eval_period": 20,
    "job_id": "dev",
    "labels": {},
    "manager_args": {
     "eps": 0.2,
     "gamma": 1,
     "model_args": {
      "add_edge_model": false,
      "add_global_model": false,
      "add_rnn": false,
      "b_encoding": [
       {
        "encoding": "onehot",
        "n_levels": 16,
        "name": "round_number"
       }
      ],
      "hidden_size": 5,
      "x_encoding": [
       {
        "encoding": "numeric",
        "n_levels": 21,
        "name": "contributions"
       }
      ]
     },
     "opt_args": {
      "lr": 0.003
     },
     "target_update_freq": 20
    },
    "n_update_steps": 1000,
    "replay_memory_args": {
     "n_episodes": 100
    }
   },
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "83484b78e3eced0c1ebbaf37dd8049c2f9102f6dcade2a60a08a368fc0daac5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
