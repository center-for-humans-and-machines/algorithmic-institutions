{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b173f42",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "artificial_humans = \"../../artifacts/artificial_humans/03_dataset/model/dataset_all.pt\"\n",
    "artificial_humans_valid = \"../../artifacts/artificial_humans/02_2_valid/model/rnn_True.pt\"\n",
    "artificial_humans_model = \"graph\"\n",
    "data_dir = \"../../data/manager_v3/dev/\"\n",
    "manager_args = {\n",
    "    \"opt_args\": {\"lr\": 0.003},\n",
    "    \"gamma\": 1.0,\n",
    "    \"eps\": 0.2,\n",
    "    \"target_update_freq\": 20,\n",
    "    \"model_args\": {\n",
    "        \"hidden_size\": 5,\n",
    "        \"add_rnn\": False,\n",
    "        \"add_edge_model\": False,\n",
    "        \"add_global_model\": False,\n",
    "        \"x_encoding\": [\n",
    "            {\"name\": \"contributions\", \"n_levels\": 21, \"encoding\": \"numeric\"},\n",
    "            {\"name\":\"is_first\", \"etype\": 'bool' }\n",
    "        ],\n",
    "        \"b_encoding\": [{\"name\": \"round_number\", \"n_levels\": 16, \"encoding\": \"onehot\"}],\n",
    "    },\n",
    "}\n",
    "replay_memory_args = {\"n_episodes\": 100}\n",
    "n_update_steps = 50\n",
    "eval_period = 2\n",
    "env_args = {\n",
    "    \"n_agents\": 4,\n",
    "    \"n_contributions\": 21,\n",
    "    \"n_punishments\": 31,\n",
    "    \"n_rounds\": 16,\n",
    "    \"batch_size\": 1000,\n",
    "}\n",
    "device = \"cpu\"\n",
    "job_id = \"dev\"\n",
    "labels = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42c92424",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch as th\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from itertools import count\n",
    "\n",
    "from aimanager.manager.memory import Memory\n",
    "from aimanager.manager.environment import ArtificialHumanEnv\n",
    "from aimanager.artificial_humans import AH_MODELS\n",
    "from aimanager.manager.manager import ArtificalManager\n",
    "from aimanager.utils.utils import make_dir\n",
    "from aimanager.utils.array_to_df import add_labels\n",
    "\n",
    "metrics_dir = os.path.join(data_dir, 'metrics')\n",
    "model_dir = os.path.join(data_dir, 'model')\n",
    "make_dir(metrics_dir)\n",
    "make_dir(model_dir)\n",
    "\n",
    "\n",
    "th.random.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9400cf5",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "rec_keys = [\n",
    "    'punishments', 'contributions', 'common_good', 'contributor_payoff', 'manager_payoff']\n",
    "\n",
    "def run_batch(manager, env, replay_mem=None, on_policy=True, update_step=None):\n",
    "\n",
    "    state = env.reset()\n",
    "    metric_list = []\n",
    "    for round_number in count():\n",
    "        _state = {**state, **env.get_batch_structure()}\n",
    "        encoded = manager.encode_pure(_state)\n",
    "\n",
    "        # Get q values from controller\n",
    "        q_values = manager.get_q(encoded, first=round_number == 0)\n",
    "    \n",
    "        if on_policy:\n",
    "            action = q_values.argmax(-1)\n",
    "        else:\n",
    "            # Sample a action\n",
    "            action = manager.eps_greedy(q_values=q_values)\n",
    "\n",
    "        state = env.punish(action)\n",
    "        \n",
    "        metrics = {k: state[k].to(th.float).mean().item() for k in rec_keys}\n",
    "\n",
    "        # pass actions to environment and advance by one step\n",
    "        state, reward, done = env.step()\n",
    "        if replay_mem is not None:\n",
    "            replay_mem.add(\n",
    "                episode_step=round_number, action=action, reward=reward, \n",
    "                **{k:v for k, v in encoded.items() if k not in ['edge_index', 'batch']})\n",
    "\n",
    "        metrics['next_reward'] = reward.mean().item()\n",
    "        metrics['q_min'] = q_values.min().item()\n",
    "        metrics['q_max'] = q_values.max().item()\n",
    "        metrics['q_mean'] = q_values.mean().item()\n",
    "        metrics['round_number'] = round_number\n",
    "        metrics['sampling'] = 'greedy' if on_policy else 'eps-greedy'\n",
    "        metrics['update_step'] = update_step\n",
    "        metric_list.append(metrics)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    return metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02d293a0",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GraphNetwork' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/torch/serialization.py:309\u001b[0m, in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 309\u001b[0m     f\u001b[39m.\u001b[39;49mseek(f\u001b[39m.\u001b[39mtell())\n\u001b[1;32m    310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1185\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1185\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1186\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GraphNetwork' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/levinbrinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/levinbrinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m device \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mdevice(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/levinbrinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cpu \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/levinbrinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m artificial_humans \u001b[39m=\u001b[39m AH_MODELS[artificial_humans_model]\u001b[39m.\u001b[39;49mload(artificial_humans, device\u001b[39m=\u001b[39;49mdevice)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/levinbrinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m artificial_humans_valid \u001b[39m=\u001b[39m AH_MODELS[artificial_humans_model]\u001b[39m.\u001b[39mload(artificial_humans_valid, device\u001b[39m=\u001b[39mdevice)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/levinbrinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m env \u001b[39m=\u001b[39m ArtificialHumanEnv(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/levinbrinkmann/repros/algorithmic-institutions/notebooks/manager/rl_manager.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     artifical_humans\u001b[39m=\u001b[39martificial_humans, artifical_humans_valid\u001b[39m=\u001b[39martificial_humans_valid, device\u001b[39m=\u001b[39mdevice, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39menv_args)\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/aimanager/generic/graph.py:261\u001b[0m, in \u001b[0;36mGraphNetwork.load\u001b[0;34m(cls, filename, device)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mcls\u001b[39m, filename, device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 261\u001b[0m     to_load \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39;49mload(filename, map_location\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m    263\u001b[0m     \u001b[39m# ensure backward compatibility\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mmanager_valid\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m to_load[\u001b[39m'\u001b[39m\u001b[39mdefault_values\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/torch/serialization.py:236\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[39mreturn\u001b[39;00m _open_buffer_writer(name_or_buffer)\n\u001b[1;32m    235\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m--> 236\u001b[0m     \u001b[39mreturn\u001b[39;00m _open_buffer_reader(name_or_buffer)\n\u001b[1;32m    237\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m\u001b[39m in mode but got \u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/torch/serialization.py:221\u001b[0m, in \u001b[0;36m_open_buffer_reader.__init__\u001b[0;34m(self, buffer)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, buffer):\n\u001b[1;32m    220\u001b[0m     \u001b[39msuper\u001b[39m(_open_buffer_reader, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(buffer)\n\u001b[0;32m--> 221\u001b[0m     _check_seekable(buffer)\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/torch/serialization.py:312\u001b[0m, in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39mexcept\u001b[39;00m (io\u001b[39m.\u001b[39mUnsupportedOperation, \u001b[39mAttributeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 312\u001b[0m     raise_err_msg([\u001b[39m\"\u001b[39;49m\u001b[39mseek\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtell\u001b[39;49m\u001b[39m\"\u001b[39;49m], e)\n\u001b[1;32m    313\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/torch/serialization.py:305\u001b[0m, in \u001b[0;36m_check_seekable.<locals>.raise_err_msg\u001b[0;34m(patterns, e)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n\u001b[1;32m    302\u001b[0m         msg \u001b[39m=\u001b[39m (\u001b[39mstr\u001b[39m(e) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m. You can only torch.load from a file that is seekable.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m Please pre-load the data into a buffer like io.BytesIO and\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m try to load from it instead.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 305\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(msg)\n\u001b[1;32m    306\u001b[0m \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GraphNetwork' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead."
     ]
    }
   ],
   "source": [
    "device = th.device(device)\n",
    "cpu = th.device('cpu')\n",
    "\n",
    "artificial_humans = AH_MODELS[artificial_humans_model].load(artificial_humans, device=device).to(device)\n",
    "artificial_humans_valid = AH_MODELS[artificial_humans_model].load(artificial_humans_valid, device=device).to(device)\n",
    "\n",
    "env = ArtificialHumanEnv(\n",
    "    artifical_humans=artificial_humans, artifical_humans_valid=artificial_humans_valid, device=device, **env_args)\n",
    "\n",
    "manager = ArtificalManager(\n",
    "    n_contributions=env.n_contributions, n_punishments=env.n_punishments, \n",
    "    default_values=artificial_humans.default_values, device=device, **manager_args)\n",
    "\n",
    "replay_mem = Memory(\n",
    "    n_episode_steps=env.n_rounds, device=cpu, **replay_memory_args)\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "for update_step in range(n_update_steps):\n",
    "    # replay_mem.start_batch(env.groups)\n",
    "\n",
    "    # here we sample one batch of episodes and add them to the replay buffer\n",
    "    off_policy_metrics = run_batch(manager, env, replay_mem, on_policy=False, update_step=update_step)\n",
    "\n",
    "    replay_mem.next_episode(update_step)\n",
    "    \n",
    "    # allow manager to update itself\n",
    "    sample = replay_mem.get_random(device=device)\n",
    "    graph = env.get_batch_structure()\n",
    "\n",
    "    if sample is not None:\n",
    "        loss = manager.update(update_step, **sample, **graph)\n",
    "    \n",
    "    if (update_step % eval_period) == 0:\n",
    "        metrics_list.extend([{**m, 'loss': l.item()} for m, l in zip(off_policy_metrics, loss)])\n",
    "        metrics_list.extend(\n",
    "            run_batch(manager, env, replay_mem=None, on_policy=True, update_step=update_step))\n",
    "\n",
    "model_file = os.path.join(model_dir, f'{job_id}.pt')\n",
    "\n",
    "manager.save(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee6155e",
   "metadata": {
    "papermill": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_vars = ['round_number', 'sampling', 'update_step']\n",
    "value_vars = ['punishments', 'contributions', 'common_good', 'contributor_payoff',\n",
    "       'manager_payoff', 'next_reward', 'q_min', 'q_max', 'q_mean', 'loss']\n",
    "\n",
    "df = pd.DataFrame.from_records(metrics_list)\n",
    "\n",
    "df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='metric')\n",
    "\n",
    "df = add_labels(df, {**labels, 'job_id': job_id})\n",
    "\n",
    "df.to_parquet(os.path.join(metrics_dir, f'{job_id}.parquet'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "papermill": {
   "default_parameters": {},
   "environment_variables": {},
   "input_path": "notebooks/manager/rl_manager_v3.ipynb",
   "output_path": "notebooks/manager/rl_manager_v3.ipynb",
   "parameters": {
    "artificial_humans": "../../artifacts/artificial_humans/01_rnn_edge_features/model/rnn_True__edge_True__global_features_False.pt",
    "artificial_humans_model": "graph",
    "artificial_humans_valid": "../../artifacts/artificial_humans/02_valid/model/rnn_True.pt",
    "data_dir": "../../data/manager_v3/dev/",
    "device": "cpu",
    "env_args": {
     "batch_size": 1000,
     "n_agents": 4,
     "n_contributions": 21,
     "n_punishments": 31,
     "n_rounds": 16
    },
    "eval_period": 20,
    "job_id": "dev",
    "labels": {},
    "manager_args": {
     "eps": 0.2,
     "gamma": 1,
     "model_args": {
      "add_edge_model": false,
      "add_global_model": false,
      "add_rnn": false,
      "b_encoding": [
       {
        "encoding": "onehot",
        "n_levels": 16,
        "name": "round_number"
       }
      ],
      "hidden_size": 5,
      "x_encoding": [
       {
        "encoding": "numeric",
        "n_levels": 21,
        "name": "contributions"
       }
      ]
     },
     "opt_args": {
      "lr": 0.003
     },
     "target_update_freq": 20
    },
    "n_update_steps": 1000,
    "replay_memory_args": {
     "n_episodes": 100
    }
   },
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1198fd9370ee0cf82025240fa26724f68bfab1e3f74dbb4acdc06e7861d0dbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
