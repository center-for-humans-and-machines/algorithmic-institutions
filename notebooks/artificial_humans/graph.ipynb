{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d857fbbc",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_cross_val = 6\n",
    "fraction_training = 1.0\n",
    "data_file = \"../../data/experiments/pilot_random1_player_round_slim.csv\"\n",
    "data_dir = \"../../data/artificial_humans/dev\"\n",
    "labels = {}\n",
    "model_name = \"graph\"\n",
    "job_id = 'dev'\n",
    "model_args = {\n",
    "    \"y_levels\": 31,\n",
    "    \"y_name\": \"punishments\",\n",
    "    \"add_rnn\": False,\n",
    "    \"add_edge_model\": False,\n",
    "    \"add_global_model\": False,\n",
    "    \"hidden_size\": 10,\n",
    "    \"x_encoding\": [\n",
    "        {\"name\": \"prev_contributions\", \"n_levels\": 21, \"encoding\": \"numeric\"},\n",
    "        {\"name\": \"prev_punishments\", \"n_levels\": 31, \"encoding\": \"numeric\"},\n",
    "        {\"name\": \"prev_valid\", \"etype\": \"bool\"},\n",
    "    ],\n",
    "    \"u_encoding\": [\n",
    "        {\"name\": \"prev_common_good\", \"norm\": 32, \"etype\": \"float\"},\n",
    "        {\"name\": \"round_number\", \"n_levels\": 16, \"encoding\": \"numeric\"},\n",
    "    ],\n",
    "}\n",
    "mask_name = \"manager_valid\"\n",
    "experiment_names = [\"trail_rounds_2\"]\n",
    "optimizer_args = {\"lr\": 0.001, \"weight_decay\": 1e-05}\n",
    "train_args = {\"epochs\": 100, \"batch_size\": 20, \"clamp_grad\": 1, \"eval_period\": 10, 'l1_entropy': 0.1}\n",
    "n_player = 4\n",
    "shuffle_features = [\"prev_punishments\", \"prev_contributions\", \"prev_common_good\"]\n",
    "device = \"cpu\"\n",
    "seed = 123\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44582683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T12:01:35.913454Z",
     "iopub.status.busy": "2022-06-30T12:01:35.913043Z",
     "iopub.status.idle": "2022-06-30T12:01:38.252980Z",
     "shell.execute_reply": "2022-06-30T12:01:38.252329Z"
    },
    "papermill": {
     "duration": 2.3494,
     "end_time": "2022-06-30T12:01:38.255085",
     "exception": false,
     "start_time": "2022-06-30T12:01:35.905685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch as th\n",
    "from aimanager.generic.data import create_torch_data, get_cross_validations\n",
    "from aimanager.artificial_humans import AH_MODELS\n",
    "from aimanager.artificial_humans.evaluation import Evaluator\n",
    "from aimanager.utils.array_to_df import using_multiindex\n",
    "from aimanager.utils.utils import make_dir\n",
    "from aimanager.generic.graph_encode import create_fully_connected\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "model_dir = os.path.join(data_dir, 'model')\n",
    "make_dir(model_dir)\n",
    "\n",
    "th.random.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6659c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T12:01:38.262665Z",
     "iopub.status.busy": "2022-06-30T12:01:38.262184Z",
     "iopub.status.idle": "2022-06-30T12:02:01.031743Z",
     "shell.execute_reply": "2022-06-30T12:02:01.031064Z"
    },
    "papermill": {
     "duration": 22.77529,
     "end_time": "2022-06-30T12:02:01.033741",
     "exception": false,
     "start_time": "2022-06-30T12:01:38.258451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file)\n",
    "\n",
    "df = df[df['experiment_name'].isin(experiment_names)]\n",
    "\n",
    "data, default_values = create_torch_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f144b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T12:02:01.072488Z",
     "iopub.status.busy": "2022-06-30T12:02:01.072155Z",
     "iopub.status.idle": "2022-06-30T12:07:48.970453Z",
     "shell.execute_reply": "2022-06-30T12:07:48.969564Z"
    },
    "papermill": {
     "duration": 347.93606,
     "end_time": "2022-06-30T12:07:48.972626",
     "exception": false,
     "start_time": "2022-06-30T12:02:01.036566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 0 | Epoch 0 | Loss 3.0484092831611633\n",
      "CV 0 | Epoch 10 | Loss 2.9083509743213654\n",
      "CV 0 | Epoch 20 | Loss 2.6440625488758087\n",
      "CV 0 | Epoch 30 | Loss 2.3037593454122542\n",
      "CV 0 | Epoch 40 | Loss 1.94591127038002\n",
      "CV 0 | Epoch 50 | Loss 1.697283399105072\n",
      "CV 0 | Epoch 60 | Loss 1.5848568767309188\n",
      "CV 0 | Epoch 70 | Loss 1.5421271115541457\n",
      "CV 0 | Epoch 80 | Loss 1.529322651028633\n",
      "CV 0 | Epoch 90 | Loss 1.5164063811302184\n",
      "CV 0 | Epoch 99 | Loss 1.5098525716198816\n",
      "CV 1 | Epoch 0 | Loss 3.0827666521072388\n",
      "CV 1 | Epoch 10 | Loss 2.9269097328186033\n",
      "CV 1 | Epoch 20 | Loss 2.5857708394527434\n",
      "CV 1 | Epoch 30 | Loss 2.187081587314606\n",
      "CV 1 | Epoch 40 | Loss 1.8409979552030564\n",
      "CV 1 | Epoch 50 | Loss 1.6327205091714858\n",
      "CV 1 | Epoch 60 | Loss 1.5663266003131866\n",
      "CV 1 | Epoch 70 | Loss 1.5276067346334457\n",
      "CV 1 | Epoch 80 | Loss 1.523830282688141\n",
      "CV 1 | Epoch 90 | Loss 1.5104892671108245\n",
      "CV 1 | Epoch 99 | Loss 1.506388823191325\n",
      "CV 2 | Epoch 0 | Loss 2.9473024010658264\n",
      "CV 2 | Epoch 10 | Loss 2.7572209537029266\n",
      "CV 2 | Epoch 20 | Loss 2.405383586883545\n",
      "CV 2 | Epoch 30 | Loss 2.0559731900691984\n",
      "CV 2 | Epoch 40 | Loss 1.7747741729021071\n",
      "CV 2 | Epoch 50 | Loss 1.6293352454900742\n",
      "CV 2 | Epoch 60 | Loss 1.567753341794014\n",
      "CV 2 | Epoch 70 | Loss 1.5231609761714935\n",
      "CV 2 | Epoch 80 | Loss 1.5176152884960175\n",
      "CV 2 | Epoch 90 | Loss 1.5002856105566025\n",
      "CV 2 | Epoch 99 | Loss 1.4873517751693726\n",
      "CV 3 | Epoch 0 | Loss 2.9548535346984863\n",
      "CV 3 | Epoch 10 | Loss 2.7596800923347473\n",
      "CV 3 | Epoch 20 | Loss 2.42528715133667\n",
      "CV 3 | Epoch 30 | Loss 2.0949305415153505\n",
      "CV 3 | Epoch 40 | Loss 1.8124399960041047\n",
      "CV 3 | Epoch 50 | Loss 1.6170222222805024\n",
      "CV 3 | Epoch 60 | Loss 1.5345377892255783\n",
      "CV 3 | Epoch 70 | Loss 1.4981118708848953\n",
      "CV 3 | Epoch 80 | Loss 1.4978595942258834\n",
      "CV 3 | Epoch 90 | Loss 1.473424282670021\n",
      "CV 3 | Epoch 99 | Loss 1.4679810437891219\n",
      "CV 4 | Epoch 0 | Loss 3.172093152999878\n",
      "CV 4 | Epoch 10 | Loss 2.975084036588669\n",
      "CV 4 | Epoch 20 | Loss 2.646567016839981\n",
      "CV 4 | Epoch 30 | Loss 2.321057307720184\n",
      "CV 4 | Epoch 40 | Loss 2.0057227969169618\n",
      "CV 4 | Epoch 50 | Loss 1.7700760811567307\n",
      "CV 4 | Epoch 60 | Loss 1.629607266187668\n",
      "CV 4 | Epoch 70 | Loss 1.548133021593094\n",
      "CV 4 | Epoch 80 | Loss 1.522733986377716\n",
      "CV 4 | Epoch 90 | Loss 1.502079290151596\n",
      "CV 4 | Epoch 99 | Loss 1.4813687437110477\n",
      "CV 5 | Epoch 0 | Loss 3.1079570055007935\n",
      "CV 5 | Epoch 10 | Loss 2.9210032761096953\n",
      "CV 5 | Epoch 20 | Loss 2.5412130892276763\n",
      "CV 5 | Epoch 30 | Loss 2.1386358022689818\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/artificial_humans/graph.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/artificial_humans/graph.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m mask \u001b[39m=\u001b[39m batch_data[\u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/artificial_humans/graph.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m loss \u001b[39m=\u001b[39m (loss \u001b[39m*\u001b[39m mask)\u001b[39m.\u001b[39msum() \u001b[39m/\u001b[39m mask\u001b[39m.\u001b[39msum()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/artificial_humans/graph.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/artificial_humans/graph.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39mif\u001b[39;00m train_args[\u001b[39m'\u001b[39m\u001b[39mclamp_grad\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bcluster/home/mpib/brinkmann/repros/algorithmic-institutions/notebooks/artificial_humans/graph.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters():\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "th_device = th.device(device)\n",
    "\n",
    "metrics = []\n",
    "confusion_matrix = []\n",
    "syn_pred = []\n",
    "ev = Evaluator()\n",
    "\n",
    "th_device = th.device(device)\n",
    "\n",
    "syn_index = ['prev_punishments', 'prev_contributions']\n",
    "edge_index = create_fully_connected(n_player)\n",
    "\n",
    "\n",
    "def shuffle_feature(data, feature_name):\n",
    "    data = {**data}\n",
    "    data[feature_name] = data[feature_name][th.randperm(len(data[feature_name]))]\n",
    "    return data\n",
    "\n",
    "for i, train_data, test_data in get_cross_validations(data, n_cross_val, fraction_training):\n",
    "    model = AH_MODELS[model_name](default_values=default_values, **model_args).to(th_device)\n",
    "\n",
    "    train_data_ = model.encode(train_data, mask=mask_name, edge_index=edge_index)\n",
    "    if test_data is not None:\n",
    "        test_data_ = model.encode(test_data, mask=mask_name, edge_index=edge_index)\n",
    "\n",
    "    optimizer = th.optim.Adam(model.parameters(), **optimizer_args)\n",
    "    loss_fn = th.nn.CrossEntropyLoss(reduction='none')\n",
    "    sum_loss = 0\n",
    "    n_steps = 0\n",
    "\n",
    "    for e in range(train_args['epochs']):\n",
    "        ev.set_labels(cv_split=i, epoch=e)\n",
    "        model.train()\n",
    "        for j, batch_data in enumerate(iter(DataLoader(train_data_, shuffle=True, batch_size=train_args['batch_size']))):\n",
    "            optimizer.zero_grad()\n",
    "            py = model(batch_data).flatten(end_dim=-2)\n",
    "            y_true = batch_data['y_enc'].flatten(end_dim=-2)\n",
    "            py_soft = py.softmax(-1)\n",
    "            loss = loss_fn(py, y_true) + (py_soft * py_soft.log()).sum(-1) * train_args['l1_entropy']\n",
    "\n",
    "            mask = batch_data['mask'].flatten()\n",
    "            loss = (loss * mask).sum() / mask.sum()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if train_args['clamp_grad']:\n",
    "                for param in model.parameters():\n",
    "                    param.grad.data.clamp_(-train_args['clamp_grad'], train_args['clamp_grad'])\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()\n",
    "            n_steps +=1\n",
    "        \n",
    "        last_epoch = e == (train_args['epochs'] - 1)\n",
    "\n",
    "        if (e % train_args['eval_period'] == 0) or last_epoch:\n",
    "            avg_loss = sum_loss/n_steps\n",
    "            print(f'CV {i} | Epoch {e} | Loss {avg_loss}')\n",
    "            ev.add_loss(avg_loss)\n",
    "\n",
    "            ev.eval_set(model, train_data_, calc_confusion=last_epoch, set='train')\n",
    "            if test_data is not None:\n",
    "                ev.eval_set(model, test_data_, calc_confusion=last_epoch, set='test')\n",
    "                for sf in shuffle_features:\n",
    "                    shuffled_data = shuffle_feature(test_data, sf)\n",
    "                    shuffled_data = model.encode(shuffled_data, mask=mask_name, edge_index=edge_index)\n",
    "                    ev.eval_set(model, shuffled_data, calc_confusion=False, set='test', shuffle_feature=sf)\n",
    "            sum_loss = 0\n",
    "            n_steps = 0\n",
    "\n",
    "    if i is None:\n",
    "        ev.save(data_dir, labels, job_id=job_id)\n",
    "        model_path = os.path.join(model_dir, f'{job_id}.pt')\n",
    "        model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30035041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2116, 0.0491, 0.0426,  ..., 0.0314, 0.0143, 0.0182],\n",
       "        [0.4488, 0.0508, 0.0461,  ..., 0.0171, 0.0075, 0.0094],\n",
       "        [0.4519, 0.0503, 0.0461,  ..., 0.0166, 0.0075, 0.0095],\n",
       "        ...,\n",
       "        [0.2393, 0.0499, 0.0429,  ..., 0.0276, 0.0132, 0.0191],\n",
       "        [0.4461, 0.0502, 0.0467,  ..., 0.0155, 0.0078, 0.0103],\n",
       "        [0.4383, 0.0506, 0.0461,  ..., 0.0155, 0.0079, 0.0108]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.softmax(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 376.216797,
   "end_time": "2022-06-30T12:07:50.559416",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/artificial_humans/graph.ipynb",
   "output_path": "notebooks/artificial_humans/graph.ipynb",
   "parameters": {
    "data_file": "../../data/experiments/pilot_random1_player_round_slim.csv",
    "device": "cpu",
    "experiment_names": [
     "trail_rounds_2"
    ],
    "fraction_training": 1,
    "labels": {},
    "mask_name": "manager_valid",
    "model_args": {
     "add_edge_model": false,
     "add_global_model": false,
     "add_rnn": false,
     "hidden_size": 10,
     "u_encoding": [
      {
       "etype": "float",
       "name": "prev_common_good",
       "norm": 32
      },
      {
       "encoding": "numeric",
       "n_levels": 16,
       "name": "round_number"
      }
     ],
     "x_encoding": [
      {
       "encoding": "numeric",
       "n_levels": 21,
       "name": "prev_contributions"
      },
      {
       "encoding": "numeric",
       "n_levels": 31,
       "name": "prev_punishments"
      },
      {
       "etype": "bool",
       "name": "prev_valid"
      }
     ],
     "y_levels": 31,
     "y_name": "punishments"
    },
    "model_name": "graph",
    "n_cross_val": 2,
    "n_player": 4,
    "optimizer_args": {
     "lr": 0.0001,
     "weight_decay": 0.00001
    },
    "output_path": "../../data/training/dev",
    "shuffle_features": [
     "prev_punishments",
     "prev_contributions",
     "prev_common_good"
    ],
    "train_args": {
     "batch_size": 20,
     "clamp_grad": 1,
     "epochs": 100,
     "eval_period": 10
    }
   },
   "start_time": "2022-06-30T12:01:34.342619",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "83484b78e3eced0c1ebbaf37dd8049c2f9102f6dcade2a60a08a368fc0daac5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
