{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d857fbbc",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_cross_val = 6\n",
    "fraction_training = 1.0\n",
    "data_file = \"../../data/experiments/pilot_random1_player_round_slim.csv\"\n",
    "output_path = \"../../data/training/dev\"\n",
    "labels = {}\n",
    "model_name = \"graph\"\n",
    "model_args = {\n",
    "    \"y_levels\": 31,\n",
    "    \"y_name\": \"punishments\",\n",
    "    \"add_rnn\": False,\n",
    "    \"add_edge_model\": False,\n",
    "    \"add_global_model\": False,\n",
    "    \"hidden_size\": 10,\n",
    "    \"x_encoding\": [\n",
    "        {\"name\": \"prev_contributions\", \"n_levels\": 21, \"encoding\": \"numeric\"},\n",
    "        {\"name\": \"prev_punishments\", \"n_levels\": 31, \"encoding\": \"numeric\"},\n",
    "        {\"name\": \"prev_valid\", \"etype\": \"bool\"},\n",
    "    ],\n",
    "    \"u_encoding\": [\n",
    "        {\"name\": \"prev_common_good\", \"norm\": 32, \"etype\": \"float\"},\n",
    "        {\"name\": \"round_number\", \"n_levels\": 16, \"encoding\": \"numeric\"},\n",
    "    ],\n",
    "}\n",
    "mask_name = \"manager_valid\"\n",
    "experiment_names = [\"trail_rounds_2\"]\n",
    "optimizer_args = {\"lr\": 0.001, \"weight_decay\": 1e-05}\n",
    "train_args = {\"epochs\": 1000, \"batch_size\": 20, \"clamp_grad\": 1, \"eval_period\": 10}\n",
    "n_player = 4\n",
    "shuffle_features = [\"prev_punishments\", \"prev_contributions\", \"prev_common_good\"]\n",
    "device = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44582683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T12:01:35.913454Z",
     "iopub.status.busy": "2022-06-30T12:01:35.913043Z",
     "iopub.status.idle": "2022-06-30T12:01:38.252980Z",
     "shell.execute_reply": "2022-06-30T12:01:38.252329Z"
    },
    "papermill": {
     "duration": 2.3494,
     "end_time": "2022-06-30T12:01:38.255085",
     "exception": false,
     "start_time": "2022-06-30T12:01:35.905685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpib/brinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mpib/brinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch as th\n",
    "from aimanager.generic.data import create_syn_data, create_torch_data, get_cross_validations\n",
    "from aimanager.artificial_humans import AH_MODELS\n",
    "from aimanager.artificial_humans.evaluation import Evaluator\n",
    "from aimanager.utils.array_to_df import using_multiindex\n",
    "from aimanager.generic.graph_encode import create_fully_connected\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "output_path = os.path.join(output_path, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6659c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T12:01:38.262665Z",
     "iopub.status.busy": "2022-06-30T12:01:38.262184Z",
     "iopub.status.idle": "2022-06-30T12:02:01.031743Z",
     "shell.execute_reply": "2022-06-30T12:02:01.031064Z"
    },
    "papermill": {
     "duration": 22.77529,
     "end_time": "2022-06-30T12:02:01.033741",
     "exception": false,
     "start_time": "2022-06-30T12:01:38.258451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file)\n",
    "\n",
    "df = df[df['experiment_name'].isin(experiment_names)]\n",
    "\n",
    "data, default_values = create_torch_data(df)\n",
    "# syn_data = create_syn_data(n_contribution=21, n_punishment=31, default_values=default_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f144b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T12:02:01.072488Z",
     "iopub.status.busy": "2022-06-30T12:02:01.072155Z",
     "iopub.status.idle": "2022-06-30T12:07:48.970453Z",
     "shell.execute_reply": "2022-06-30T12:07:48.969564Z"
    },
    "papermill": {
     "duration": 347.93606,
     "end_time": "2022-06-30T12:07:48.972626",
     "exception": false,
     "start_time": "2022-06-30T12:02:01.036566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 0 | Epoch 0 | Loss 3.3330878615379333\n",
      "CV 0 | Epoch 10 | Loss 3.237093299627304\n",
      "CV 0 | Epoch 20 | Loss 3.069940757751465\n",
      "CV 0 | Epoch 30 | Loss 2.874095231294632\n",
      "CV 0 | Epoch 40 | Loss 2.629763603210449\n",
      "CV 0 | Epoch 50 | Loss 2.31423679292202\n",
      "CV 0 | Epoch 60 | Loss 1.9851505368947984\n",
      "CV 0 | Epoch 70 | Loss 1.7868253618478775\n",
      "CV 0 | Epoch 80 | Loss 1.729209867119789\n",
      "CV 0 | Epoch 90 | Loss 1.690979266166687\n",
      "CV 0 | Epoch 100 | Loss 1.6810075849294663\n",
      "CV 0 | Epoch 110 | Loss 1.6635765552520752\n",
      "CV 0 | Epoch 120 | Loss 1.649100336432457\n",
      "CV 0 | Epoch 130 | Loss 1.6425791323184966\n",
      "CV 0 | Epoch 140 | Loss 1.6309231400489808\n",
      "CV 0 | Epoch 150 | Loss 1.6336711943149567\n",
      "CV 0 | Epoch 160 | Loss 1.6301698982715607\n",
      "CV 0 | Epoch 170 | Loss 1.6212908953428269\n",
      "CV 0 | Epoch 180 | Loss 1.6101555913686751\n",
      "CV 0 | Epoch 190 | Loss 1.613551491498947\n",
      "CV 0 | Epoch 200 | Loss 1.6055276542901993\n",
      "CV 0 | Epoch 210 | Loss 1.6021727234125138\n",
      "CV 0 | Epoch 220 | Loss 1.596126389503479\n",
      "CV 0 | Epoch 230 | Loss 1.5904176831245422\n",
      "CV 0 | Epoch 240 | Loss 1.5909509778022766\n",
      "CV 0 | Epoch 250 | Loss 1.5896380603313447\n",
      "CV 0 | Epoch 260 | Loss 1.573847496509552\n",
      "CV 0 | Epoch 270 | Loss 1.5882267981767655\n",
      "CV 0 | Epoch 280 | Loss 1.584047305583954\n",
      "CV 0 | Epoch 290 | Loss 1.578595021367073\n",
      "CV 0 | Epoch 300 | Loss 1.5894825458526611\n",
      "CV 0 | Epoch 310 | Loss 1.5864233762025832\n",
      "CV 0 | Epoch 320 | Loss 1.5712168306112289\n",
      "CV 0 | Epoch 330 | Loss 1.5839344710111618\n",
      "CV 0 | Epoch 340 | Loss 1.5654555171728135\n",
      "CV 0 | Epoch 350 | Loss 1.5738578736782074\n",
      "CV 0 | Epoch 360 | Loss 1.563794094324112\n",
      "CV 0 | Epoch 370 | Loss 1.5807178050279618\n",
      "CV 0 | Epoch 380 | Loss 1.5645873904228211\n",
      "CV 0 | Epoch 390 | Loss 1.5773209363222123\n",
      "CV 0 | Epoch 400 | Loss 1.580860623717308\n",
      "CV 0 | Epoch 410 | Loss 1.5739028096199035\n",
      "CV 0 | Epoch 420 | Loss 1.5865549832582473\n",
      "CV 0 | Epoch 430 | Loss 1.5718199223279954\n",
      "CV 0 | Epoch 440 | Loss 1.5736503213644029\n",
      "CV 0 | Epoch 450 | Loss 1.5563518524169921\n",
      "CV 0 | Epoch 460 | Loss 1.5693139374256133\n",
      "CV 0 | Epoch 470 | Loss 1.5672761976718903\n",
      "CV 0 | Epoch 480 | Loss 1.5791942715644836\n",
      "CV 0 | Epoch 490 | Loss 1.555323302745819\n",
      "CV 0 | Epoch 500 | Loss 1.5533190935850143\n",
      "CV 0 | Epoch 510 | Loss 1.5659945160150528\n",
      "CV 0 | Epoch 520 | Loss 1.5560476064682007\n",
      "CV 0 | Epoch 530 | Loss 1.551711642742157\n",
      "CV 0 | Epoch 540 | Loss 1.567554920911789\n",
      "CV 0 | Epoch 550 | Loss 1.5752470552921296\n",
      "CV 0 | Epoch 560 | Loss 1.5566036641597747\n",
      "CV 0 | Epoch 570 | Loss 1.5488183915615081\n",
      "CV 0 | Epoch 580 | Loss 1.543847280740738\n",
      "CV 0 | Epoch 590 | Loss 1.5356336861848832\n",
      "CV 0 | Epoch 600 | Loss 1.5326771140098572\n",
      "CV 0 | Epoch 610 | Loss 1.5418810427188874\n",
      "CV 0 | Epoch 620 | Loss 1.5505908846855163\n",
      "CV 0 | Epoch 630 | Loss 1.5533083498477935\n",
      "CV 0 | Epoch 640 | Loss 1.5502598762512207\n",
      "CV 0 | Epoch 650 | Loss 1.5602300673723222\n",
      "CV 0 | Epoch 660 | Loss 1.5557142525911332\n",
      "CV 0 | Epoch 670 | Loss 1.554921519756317\n",
      "CV 0 | Epoch 680 | Loss 1.533792194724083\n",
      "CV 0 | Epoch 690 | Loss 1.5490002989768983\n",
      "CV 0 | Epoch 700 | Loss 1.5535361111164092\n",
      "CV 0 | Epoch 710 | Loss 1.5368275731801986\n",
      "CV 0 | Epoch 720 | Loss 1.5480139583349228\n",
      "CV 0 | Epoch 730 | Loss 1.53910191655159\n",
      "CV 0 | Epoch 740 | Loss 1.5485707432031632\n",
      "CV 0 | Epoch 750 | Loss 1.549144870042801\n",
      "CV 0 | Epoch 760 | Loss 1.5429775536060333\n",
      "CV 0 | Epoch 770 | Loss 1.528561395406723\n",
      "CV 0 | Epoch 780 | Loss 1.527926766872406\n",
      "CV 0 | Epoch 790 | Loss 1.5236138731241227\n",
      "CV 0 | Epoch 800 | Loss 1.5470219850540161\n",
      "CV 0 | Epoch 810 | Loss 1.543486014008522\n",
      "CV 0 | Epoch 820 | Loss 1.5356961339712143\n",
      "CV 0 | Epoch 830 | Loss 1.5183406621217728\n",
      "CV 0 | Epoch 840 | Loss 1.520863053202629\n",
      "CV 0 | Epoch 850 | Loss 1.517180174589157\n",
      "CV 0 | Epoch 860 | Loss 1.5242141276597976\n",
      "CV 0 | Epoch 870 | Loss 1.5213673740625382\n",
      "CV 0 | Epoch 880 | Loss 1.5122018128633499\n",
      "CV 0 | Epoch 890 | Loss 1.5185913026332856\n",
      "CV 0 | Epoch 900 | Loss 1.5018892362713814\n",
      "CV 0 | Epoch 910 | Loss 1.521281585097313\n",
      "CV 0 | Epoch 920 | Loss 1.511961078643799\n",
      "CV 0 | Epoch 930 | Loss 1.5038208544254303\n",
      "CV 0 | Epoch 940 | Loss 1.5018945589661599\n",
      "CV 0 | Epoch 950 | Loss 1.5189918339252473\n",
      "CV 0 | Epoch 960 | Loss 1.519491907954216\n",
      "CV 0 | Epoch 970 | Loss 1.504848775267601\n",
      "CV 0 | Epoch 980 | Loss 1.5208948075771331\n",
      "CV 0 | Epoch 990 | Loss 1.5166786730289459\n",
      "CV 0 | Epoch 999 | Loss 1.5253572563330333\n",
      "CV 1 | Epoch 0 | Loss 3.518063545227051\n",
      "CV 1 | Epoch 10 | Loss 3.346457576751709\n",
      "CV 1 | Epoch 20 | Loss 3.023860955238342\n",
      "CV 1 | Epoch 30 | Loss 2.668847972154617\n",
      "CV 1 | Epoch 40 | Loss 2.326077926158905\n",
      "CV 1 | Epoch 50 | Loss 2.0353660374879836\n",
      "CV 1 | Epoch 60 | Loss 1.862753427028656\n",
      "CV 1 | Epoch 70 | Loss 1.7809346348047257\n",
      "CV 1 | Epoch 80 | Loss 1.7415117800235749\n",
      "CV 1 | Epoch 90 | Loss 1.7114906311035156\n",
      "CV 1 | Epoch 100 | Loss 1.7054292261600494\n",
      "CV 1 | Epoch 110 | Loss 1.6651389002799988\n",
      "CV 1 | Epoch 120 | Loss 1.6481024146080017\n",
      "CV 1 | Epoch 130 | Loss 1.6628805458545686\n",
      "CV 1 | Epoch 140 | Loss 1.6423184275627136\n",
      "CV 1 | Epoch 150 | Loss 1.639260822534561\n",
      "CV 1 | Epoch 160 | Loss 1.6333800077438354\n",
      "CV 1 | Epoch 170 | Loss 1.6296729058027268\n",
      "CV 1 | Epoch 180 | Loss 1.6119692891836166\n",
      "CV 1 | Epoch 190 | Loss 1.616276878118515\n",
      "CV 1 | Epoch 200 | Loss 1.6060655295848847\n",
      "CV 1 | Epoch 210 | Loss 1.5996101528406144\n",
      "CV 1 | Epoch 220 | Loss 1.5904732465744018\n",
      "CV 1 | Epoch 230 | Loss 1.5971534311771394\n",
      "CV 1 | Epoch 240 | Loss 1.597380816936493\n",
      "CV 1 | Epoch 250 | Loss 1.5803214699029922\n",
      "CV 1 | Epoch 260 | Loss 1.6004072844982147\n",
      "CV 1 | Epoch 270 | Loss 1.5838968753814697\n",
      "CV 1 | Epoch 280 | Loss 1.5825627386569976\n",
      "CV 1 | Epoch 290 | Loss 1.5932870626449585\n",
      "CV 1 | Epoch 300 | Loss 1.5903158247470857\n",
      "CV 1 | Epoch 310 | Loss 1.581500044465065\n",
      "CV 1 | Epoch 320 | Loss 1.594291117787361\n",
      "CV 1 | Epoch 330 | Loss 1.5895470768213271\n",
      "CV 1 | Epoch 340 | Loss 1.5840081989765167\n",
      "CV 1 | Epoch 350 | Loss 1.5792073220014573\n",
      "CV 1 | Epoch 360 | Loss 1.5805190920829773\n",
      "CV 1 | Epoch 370 | Loss 1.587423712015152\n",
      "CV 1 | Epoch 380 | Loss 1.5722403407096863\n",
      "CV 1 | Epoch 390 | Loss 1.574558100104332\n",
      "CV 1 | Epoch 400 | Loss 1.564075666666031\n",
      "CV 1 | Epoch 410 | Loss 1.5728813856840134\n",
      "CV 1 | Epoch 420 | Loss 1.5736676782369614\n",
      "CV 1 | Epoch 430 | Loss 1.583212074637413\n",
      "CV 1 | Epoch 440 | Loss 1.5641886293888092\n",
      "CV 1 | Epoch 450 | Loss 1.5839211970567704\n",
      "CV 1 | Epoch 460 | Loss 1.5764810562133789\n",
      "CV 1 | Epoch 470 | Loss 1.568478101491928\n",
      "CV 1 | Epoch 480 | Loss 1.5658762961626054\n",
      "CV 1 | Epoch 490 | Loss 1.5666304379701614\n",
      "CV 1 | Epoch 500 | Loss 1.5723755538463593\n",
      "CV 1 | Epoch 510 | Loss 1.5650961756706239\n",
      "CV 1 | Epoch 520 | Loss 1.5633455887436867\n",
      "CV 1 | Epoch 530 | Loss 1.5629507035017014\n",
      "CV 1 | Epoch 540 | Loss 1.5695036232471467\n",
      "CV 1 | Epoch 550 | Loss 1.566370466351509\n",
      "CV 1 | Epoch 560 | Loss 1.555314987897873\n",
      "CV 1 | Epoch 570 | Loss 1.5486176699399947\n",
      "CV 1 | Epoch 580 | Loss 1.5678135842084884\n",
      "CV 1 | Epoch 590 | Loss 1.5601697593927384\n",
      "CV 1 | Epoch 600 | Loss 1.5670005291700364\n",
      "CV 1 | Epoch 610 | Loss 1.5559505462646483\n",
      "CV 1 | Epoch 620 | Loss 1.562644013762474\n",
      "CV 1 | Epoch 630 | Loss 1.5542700976133346\n",
      "CV 1 | Epoch 640 | Loss 1.56353866904974\n",
      "CV 1 | Epoch 650 | Loss 1.5545591175556184\n",
      "CV 1 | Epoch 660 | Loss 1.5494641482830047\n",
      "CV 1 | Epoch 670 | Loss 1.5499487191438674\n",
      "CV 1 | Epoch 680 | Loss 1.5565142601728439\n",
      "CV 1 | Epoch 690 | Loss 1.5677564412355423\n",
      "CV 1 | Epoch 700 | Loss 1.5631543010473252\n",
      "CV 1 | Epoch 710 | Loss 1.5581058233976364\n",
      "CV 1 | Epoch 720 | Loss 1.5662537127733231\n",
      "CV 1 | Epoch 730 | Loss 1.5645585715770722\n",
      "CV 1 | Epoch 740 | Loss 1.5520421743392945\n",
      "CV 1 | Epoch 750 | Loss 1.5354212880134583\n",
      "CV 1 | Epoch 760 | Loss 1.5500235944986342\n",
      "CV 1 | Epoch 770 | Loss 1.5459671854972838\n",
      "CV 1 | Epoch 780 | Loss 1.5471635907888412\n",
      "CV 1 | Epoch 790 | Loss 1.549851381778717\n",
      "CV 1 | Epoch 800 | Loss 1.5374799221754074\n",
      "CV 1 | Epoch 810 | Loss 1.528551459312439\n",
      "CV 1 | Epoch 820 | Loss 1.552678245306015\n",
      "CV 1 | Epoch 830 | Loss 1.5350168526172638\n",
      "CV 1 | Epoch 840 | Loss 1.5496778219938279\n",
      "CV 1 | Epoch 850 | Loss 1.5488843142986297\n",
      "CV 1 | Epoch 860 | Loss 1.546791034936905\n",
      "CV 1 | Epoch 870 | Loss 1.540621715784073\n",
      "CV 1 | Epoch 880 | Loss 1.5453016102313994\n",
      "CV 1 | Epoch 890 | Loss 1.536523175239563\n",
      "CV 1 | Epoch 900 | Loss 1.539328572154045\n",
      "CV 1 | Epoch 910 | Loss 1.5367593437433242\n",
      "CV 1 | Epoch 920 | Loss 1.5390434294939042\n",
      "CV 1 | Epoch 930 | Loss 1.5356664657592773\n",
      "CV 1 | Epoch 940 | Loss 1.540803074836731\n",
      "CV 1 | Epoch 950 | Loss 1.551107904314995\n",
      "CV 1 | Epoch 960 | Loss 1.5331610664725304\n",
      "CV 1 | Epoch 970 | Loss 1.5435267239809036\n",
      "CV 1 | Epoch 980 | Loss 1.5413427472114563\n",
      "CV 1 | Epoch 990 | Loss 1.5390638053417205\n",
      "CV 1 | Epoch 999 | Loss 1.5503065122498407\n",
      "CV 2 | Epoch 0 | Loss 3.3179497122764587\n",
      "CV 2 | Epoch 10 | Loss 3.158891350030899\n",
      "CV 2 | Epoch 20 | Loss 2.841990351676941\n",
      "CV 2 | Epoch 30 | Loss 2.446099561452866\n",
      "CV 2 | Epoch 40 | Loss 2.0536538481712343\n",
      "CV 2 | Epoch 50 | Loss 1.803768828511238\n",
      "CV 2 | Epoch 60 | Loss 1.7291840672492982\n",
      "CV 2 | Epoch 70 | Loss 1.6759642511606216\n",
      "CV 2 | Epoch 80 | Loss 1.6661864876747132\n",
      "CV 2 | Epoch 90 | Loss 1.6718890428543092\n",
      "CV 2 | Epoch 100 | Loss 1.6569080501794815\n",
      "CV 2 | Epoch 110 | Loss 1.6501337975263595\n",
      "CV 2 | Epoch 120 | Loss 1.6609282732009887\n",
      "CV 2 | Epoch 130 | Loss 1.6310071974992753\n",
      "CV 2 | Epoch 140 | Loss 1.6330616295337677\n",
      "CV 2 | Epoch 150 | Loss 1.6314125120639802\n",
      "CV 2 | Epoch 160 | Loss 1.6159692496061324\n",
      "CV 2 | Epoch 170 | Loss 1.631512588262558\n",
      "CV 2 | Epoch 180 | Loss 1.6304043918848037\n",
      "CV 2 | Epoch 190 | Loss 1.615116161108017\n",
      "CV 2 | Epoch 200 | Loss 1.6277064263820649\n",
      "CV 2 | Epoch 210 | Loss 1.6119709342718125\n",
      "CV 2 | Epoch 220 | Loss 1.6151628971099854\n",
      "CV 2 | Epoch 230 | Loss 1.6150346279144288\n",
      "CV 2 | Epoch 240 | Loss 1.623756366968155\n",
      "CV 2 | Epoch 250 | Loss 1.5956558734178543\n",
      "CV 2 | Epoch 260 | Loss 1.5881814405322074\n",
      "CV 2 | Epoch 270 | Loss 1.6052452057600022\n",
      "CV 2 | Epoch 280 | Loss 1.6058283656835557\n",
      "CV 2 | Epoch 290 | Loss 1.598801389336586\n",
      "CV 2 | Epoch 300 | Loss 1.581910789012909\n",
      "CV 2 | Epoch 310 | Loss 1.593870609998703\n",
      "CV 2 | Epoch 320 | Loss 1.595393881201744\n",
      "CV 2 | Epoch 330 | Loss 1.5960658013820648\n",
      "CV 2 | Epoch 340 | Loss 1.5949007511138915\n",
      "CV 2 | Epoch 350 | Loss 1.584224271774292\n",
      "CV 2 | Epoch 360 | Loss 1.6039781719446182\n",
      "CV 2 | Epoch 370 | Loss 1.58969207406044\n",
      "CV 2 | Epoch 380 | Loss 1.58653784096241\n",
      "CV 2 | Epoch 390 | Loss 1.5808981627225875\n",
      "CV 2 | Epoch 400 | Loss 1.576032641530037\n",
      "CV 2 | Epoch 410 | Loss 1.5859392881393433\n",
      "CV 2 | Epoch 420 | Loss 1.5769473224878312\n",
      "CV 2 | Epoch 430 | Loss 1.5683628529310227\n",
      "CV 2 | Epoch 440 | Loss 1.5767194032669067\n",
      "CV 2 | Epoch 450 | Loss 1.581331416964531\n",
      "CV 2 | Epoch 460 | Loss 1.5867314457893371\n",
      "CV 2 | Epoch 470 | Loss 1.5858022809028625\n",
      "CV 2 | Epoch 480 | Loss 1.5652899891138077\n",
      "CV 2 | Epoch 490 | Loss 1.5791950941085815\n",
      "CV 2 | Epoch 500 | Loss 1.5757565140724181\n",
      "CV 2 | Epoch 510 | Loss 1.580034801363945\n",
      "CV 2 | Epoch 520 | Loss 1.574989342689514\n",
      "CV 2 | Epoch 530 | Loss 1.5736018538475036\n",
      "CV 2 | Epoch 540 | Loss 1.572332075238228\n",
      "CV 2 | Epoch 550 | Loss 1.5624605149030686\n",
      "CV 2 | Epoch 560 | Loss 1.5797695010900497\n",
      "CV 2 | Epoch 570 | Loss 1.5707697421312332\n",
      "CV 2 | Epoch 580 | Loss 1.5660166054964066\n",
      "CV 2 | Epoch 590 | Loss 1.558155006170273\n",
      "CV 2 | Epoch 600 | Loss 1.5642384633421897\n",
      "CV 2 | Epoch 610 | Loss 1.568288540840149\n",
      "CV 2 | Epoch 620 | Loss 1.5589277476072312\n",
      "CV 2 | Epoch 630 | Loss 1.5660629570484161\n",
      "CV 2 | Epoch 640 | Loss 1.5606688767671586\n",
      "CV 2 | Epoch 650 | Loss 1.5513607025146485\n",
      "CV 2 | Epoch 660 | Loss 1.5569211184978484\n",
      "CV 2 | Epoch 670 | Loss 1.5498238578438759\n",
      "CV 2 | Epoch 680 | Loss 1.5433986842632295\n",
      "CV 2 | Epoch 690 | Loss 1.5549536377191544\n",
      "CV 2 | Epoch 700 | Loss 1.5514374762773513\n",
      "CV 2 | Epoch 710 | Loss 1.55492702126503\n",
      "CV 2 | Epoch 720 | Loss 1.5574541747570039\n",
      "CV 2 | Epoch 730 | Loss 1.5539263874292373\n",
      "CV 2 | Epoch 740 | Loss 1.5419519916176796\n",
      "CV 2 | Epoch 750 | Loss 1.5357941180467605\n",
      "CV 2 | Epoch 760 | Loss 1.5310804814100265\n",
      "CV 2 | Epoch 770 | Loss 1.5425030261278152\n",
      "CV 2 | Epoch 780 | Loss 1.5329843282699585\n",
      "CV 2 | Epoch 790 | Loss 1.5402869254350662\n",
      "CV 2 | Epoch 800 | Loss 1.541924998164177\n",
      "CV 2 | Epoch 810 | Loss 1.5398482441902162\n",
      "CV 2 | Epoch 820 | Loss 1.5369726210832595\n",
      "CV 2 | Epoch 830 | Loss 1.550779440999031\n",
      "CV 2 | Epoch 840 | Loss 1.544329358637333\n",
      "CV 2 | Epoch 850 | Loss 1.5401885658502579\n",
      "CV 2 | Epoch 860 | Loss 1.5363089203834535\n",
      "CV 2 | Epoch 870 | Loss 1.52706817984581\n",
      "CV 2 | Epoch 880 | Loss 1.5370484828948974\n",
      "CV 2 | Epoch 890 | Loss 1.5383466899394989\n",
      "CV 2 | Epoch 900 | Loss 1.5186421036720277\n",
      "CV 2 | Epoch 910 | Loss 1.5328923016786575\n",
      "CV 2 | Epoch 920 | Loss 1.5317840442061423\n",
      "CV 2 | Epoch 930 | Loss 1.5366231709718705\n",
      "CV 2 | Epoch 940 | Loss 1.5322572767734528\n",
      "CV 2 | Epoch 950 | Loss 1.5306152254343033\n",
      "CV 2 | Epoch 960 | Loss 1.5256332471966743\n",
      "CV 2 | Epoch 970 | Loss 1.5306090503931045\n",
      "CV 2 | Epoch 980 | Loss 1.5329804003238678\n",
      "CV 2 | Epoch 990 | Loss 1.5245148077607156\n",
      "CV 2 | Epoch 999 | Loss 1.5345437328020732\n",
      "CV 3 | Epoch 0 | Loss 3.472516357898712\n",
      "CV 3 | Epoch 10 | Loss 3.3617404282093046\n",
      "CV 3 | Epoch 20 | Loss 3.1030019998550413\n",
      "CV 3 | Epoch 30 | Loss 2.69921595454216\n",
      "CV 3 | Epoch 40 | Loss 2.2127319395542147\n",
      "CV 3 | Epoch 50 | Loss 1.8860289424657821\n",
      "CV 3 | Epoch 60 | Loss 1.764703780412674\n",
      "CV 3 | Epoch 70 | Loss 1.7299056768417358\n",
      "CV 3 | Epoch 80 | Loss 1.7035915315151215\n",
      "CV 3 | Epoch 90 | Loss 1.6926836043596267\n",
      "CV 3 | Epoch 100 | Loss 1.694136729836464\n",
      "CV 3 | Epoch 110 | Loss 1.67417072057724\n",
      "CV 3 | Epoch 120 | Loss 1.6819636881351472\n",
      "CV 3 | Epoch 130 | Loss 1.6807815581560135\n",
      "CV 3 | Epoch 140 | Loss 1.6831520199775696\n",
      "CV 3 | Epoch 150 | Loss 1.6708049654960633\n",
      "CV 3 | Epoch 160 | Loss 1.6673284262418746\n",
      "CV 3 | Epoch 170 | Loss 1.6624465137720108\n",
      "CV 3 | Epoch 180 | Loss 1.6601884603500365\n",
      "CV 3 | Epoch 190 | Loss 1.6611397564411163\n",
      "CV 3 | Epoch 200 | Loss 1.659160417318344\n",
      "CV 3 | Epoch 210 | Loss 1.6542080014944076\n",
      "CV 3 | Epoch 220 | Loss 1.6575426042079926\n",
      "CV 3 | Epoch 230 | Loss 1.65892393887043\n",
      "CV 3 | Epoch 240 | Loss 1.6401927649974823\n",
      "CV 3 | Epoch 250 | Loss 1.6418211460113525\n",
      "CV 3 | Epoch 260 | Loss 1.6333251744508743\n",
      "CV 3 | Epoch 270 | Loss 1.6438164830207824\n",
      "CV 3 | Epoch 280 | Loss 1.6488520085811615\n",
      "CV 3 | Epoch 290 | Loss 1.648533248901367\n",
      "CV 3 | Epoch 300 | Loss 1.6329642146825791\n",
      "CV 3 | Epoch 310 | Loss 1.639175346493721\n",
      "CV 3 | Epoch 320 | Loss 1.6298039108514786\n",
      "CV 3 | Epoch 330 | Loss 1.6365614771842956\n",
      "CV 3 | Epoch 340 | Loss 1.62018863260746\n",
      "CV 3 | Epoch 350 | Loss 1.6313193768262864\n",
      "CV 3 | Epoch 360 | Loss 1.6284493535757065\n",
      "CV 3 | Epoch 370 | Loss 1.6324974596500397\n",
      "CV 3 | Epoch 380 | Loss 1.6175136387348175\n",
      "CV 3 | Epoch 390 | Loss 1.6205005139112472\n",
      "CV 3 | Epoch 400 | Loss 1.6198269188404084\n",
      "CV 3 | Epoch 410 | Loss 1.620824748277664\n",
      "CV 3 | Epoch 420 | Loss 1.6196088999509812\n",
      "CV 3 | Epoch 430 | Loss 1.6095983296632768\n",
      "CV 3 | Epoch 440 | Loss 1.6096211075782776\n",
      "CV 3 | Epoch 450 | Loss 1.6173480957746507\n",
      "CV 3 | Epoch 460 | Loss 1.611560094356537\n",
      "CV 3 | Epoch 470 | Loss 1.6103235065937043\n",
      "CV 3 | Epoch 480 | Loss 1.6212005525827409\n",
      "CV 3 | Epoch 490 | Loss 1.6069694191217423\n",
      "CV 3 | Epoch 500 | Loss 1.607459506392479\n",
      "CV 3 | Epoch 510 | Loss 1.6101386815309524\n",
      "CV 3 | Epoch 520 | Loss 1.6067710041999816\n",
      "CV 3 | Epoch 530 | Loss 1.6043139845132828\n",
      "CV 3 | Epoch 540 | Loss 1.60109903216362\n",
      "CV 3 | Epoch 550 | Loss 1.6034430801868438\n",
      "CV 3 | Epoch 560 | Loss 1.6138722211122514\n",
      "CV 3 | Epoch 570 | Loss 1.6072752118110656\n",
      "CV 3 | Epoch 580 | Loss 1.6130809128284453\n",
      "CV 3 | Epoch 590 | Loss 1.600550475716591\n",
      "CV 3 | Epoch 600 | Loss 1.6115211755037309\n",
      "CV 3 | Epoch 610 | Loss 1.6004427015781402\n",
      "CV 3 | Epoch 620 | Loss 1.6016842663288116\n",
      "CV 3 | Epoch 630 | Loss 1.6049792647361756\n",
      "CV 3 | Epoch 640 | Loss 1.592373976111412\n",
      "CV 3 | Epoch 650 | Loss 1.5954865634441375\n",
      "CV 3 | Epoch 660 | Loss 1.608338361978531\n",
      "CV 3 | Epoch 670 | Loss 1.6058986067771912\n",
      "CV 3 | Epoch 680 | Loss 1.603508859872818\n",
      "CV 3 | Epoch 690 | Loss 1.5907435715198517\n",
      "CV 3 | Epoch 700 | Loss 1.6057823419570922\n",
      "CV 3 | Epoch 710 | Loss 1.598972997069359\n",
      "CV 3 | Epoch 720 | Loss 1.5880737483501435\n",
      "CV 3 | Epoch 730 | Loss 1.597170916199684\n",
      "CV 3 | Epoch 740 | Loss 1.5861735939979553\n",
      "CV 3 | Epoch 750 | Loss 1.6039757758378983\n",
      "CV 3 | Epoch 760 | Loss 1.593304118514061\n",
      "CV 3 | Epoch 770 | Loss 1.5833589255809783\n",
      "CV 3 | Epoch 780 | Loss 1.5933564245700835\n",
      "CV 3 | Epoch 790 | Loss 1.589095377922058\n",
      "CV 3 | Epoch 800 | Loss 1.5974415630102157\n",
      "CV 3 | Epoch 810 | Loss 1.5939775228500366\n",
      "CV 3 | Epoch 820 | Loss 1.5928955614566802\n",
      "CV 3 | Epoch 830 | Loss 1.5903012722730636\n",
      "CV 3 | Epoch 840 | Loss 1.5884839326143265\n",
      "CV 3 | Epoch 850 | Loss 1.5893589079380035\n",
      "CV 3 | Epoch 860 | Loss 1.5861789613962174\n",
      "CV 3 | Epoch 870 | Loss 1.5867538064718247\n",
      "CV 3 | Epoch 880 | Loss 1.5952964127063751\n",
      "CV 3 | Epoch 890 | Loss 1.5945064455270768\n",
      "CV 3 | Epoch 900 | Loss 1.5752588093280793\n",
      "CV 3 | Epoch 910 | Loss 1.5812504321336747\n",
      "CV 3 | Epoch 920 | Loss 1.5940096467733382\n",
      "CV 3 | Epoch 930 | Loss 1.5769494980573655\n",
      "CV 3 | Epoch 940 | Loss 1.5875563979148866\n",
      "CV 3 | Epoch 950 | Loss 1.6043731421232224\n",
      "CV 3 | Epoch 960 | Loss 1.5897458612918853\n",
      "CV 3 | Epoch 970 | Loss 1.5857155799865723\n",
      "CV 3 | Epoch 980 | Loss 1.579310068488121\n",
      "CV 3 | Epoch 990 | Loss 1.584160476922989\n",
      "CV 3 | Epoch 999 | Loss 1.5936031738917034\n",
      "CV 4 | Epoch 0 | Loss 3.0574339628219604\n",
      "CV 4 | Epoch 10 | Loss 2.939957690238953\n",
      "CV 4 | Epoch 20 | Loss 2.6812571465969084\n",
      "CV 4 | Epoch 30 | Loss 2.343124362826347\n",
      "CV 4 | Epoch 40 | Loss 2.012372872233391\n",
      "CV 4 | Epoch 50 | Loss 1.8363243281841277\n",
      "CV 4 | Epoch 60 | Loss 1.7664209663867951\n",
      "CV 4 | Epoch 70 | Loss 1.7492544203996658\n",
      "CV 4 | Epoch 80 | Loss 1.7513442009687423\n",
      "CV 4 | Epoch 90 | Loss 1.7329074025154114\n",
      "CV 4 | Epoch 100 | Loss 1.718367400765419\n",
      "CV 4 | Epoch 110 | Loss 1.715741041302681\n",
      "CV 4 | Epoch 120 | Loss 1.7169243752956391\n",
      "CV 4 | Epoch 130 | Loss 1.6931887447834015\n",
      "CV 4 | Epoch 140 | Loss 1.69937863945961\n",
      "CV 4 | Epoch 150 | Loss 1.700406986474991\n",
      "CV 4 | Epoch 160 | Loss 1.7028768092393876\n",
      "CV 4 | Epoch 170 | Loss 1.6983018904924392\n",
      "CV 4 | Epoch 180 | Loss 1.6957659512758254\n",
      "CV 4 | Epoch 190 | Loss 1.6934817254543304\n",
      "CV 4 | Epoch 200 | Loss 1.6918689280748367\n",
      "CV 4 | Epoch 210 | Loss 1.678291028738022\n",
      "CV 4 | Epoch 220 | Loss 1.6782295852899551\n",
      "CV 4 | Epoch 230 | Loss 1.6872553288936616\n",
      "CV 4 | Epoch 240 | Loss 1.6902559459209443\n",
      "CV 4 | Epoch 250 | Loss 1.6912842303514481\n",
      "CV 4 | Epoch 260 | Loss 1.684016114473343\n",
      "CV 4 | Epoch 270 | Loss 1.6786172568798066\n",
      "CV 4 | Epoch 280 | Loss 1.6729071199893952\n",
      "CV 4 | Epoch 290 | Loss 1.6674334764480592\n",
      "CV 4 | Epoch 300 | Loss 1.6817529261112214\n",
      "CV 4 | Epoch 310 | Loss 1.6686352342367172\n",
      "CV 4 | Epoch 320 | Loss 1.6589650124311448\n",
      "CV 4 | Epoch 330 | Loss 1.6757860511541367\n",
      "CV 4 | Epoch 340 | Loss 1.670814538002014\n",
      "CV 4 | Epoch 350 | Loss 1.6647015541791916\n",
      "CV 4 | Epoch 360 | Loss 1.6787858098745345\n",
      "CV 4 | Epoch 370 | Loss 1.676272252202034\n",
      "CV 4 | Epoch 380 | Loss 1.6642880409955978\n",
      "CV 4 | Epoch 390 | Loss 1.6796198159456253\n",
      "CV 4 | Epoch 400 | Loss 1.6548518061637878\n",
      "CV 4 | Epoch 410 | Loss 1.6732685089111328\n",
      "CV 4 | Epoch 420 | Loss 1.666538354754448\n",
      "CV 4 | Epoch 430 | Loss 1.6543906778097153\n",
      "CV 4 | Epoch 440 | Loss 1.6711232960224152\n",
      "CV 4 | Epoch 450 | Loss 1.6665838658809662\n",
      "CV 4 | Epoch 460 | Loss 1.6661349326372146\n",
      "CV 4 | Epoch 470 | Loss 1.6662468582391738\n",
      "CV 4 | Epoch 480 | Loss 1.6515736818313598\n",
      "CV 4 | Epoch 490 | Loss 1.6673336654901505\n",
      "CV 4 | Epoch 500 | Loss 1.6523502469062805\n",
      "CV 4 | Epoch 510 | Loss 1.657679510116577\n",
      "CV 4 | Epoch 520 | Loss 1.6730249047279357\n",
      "CV 4 | Epoch 530 | Loss 1.6564990520477294\n",
      "CV 4 | Epoch 540 | Loss 1.6543525069952012\n",
      "CV 4 | Epoch 550 | Loss 1.6540096610784532\n",
      "CV 4 | Epoch 560 | Loss 1.6443117529153823\n",
      "CV 4 | Epoch 570 | Loss 1.6579843640327454\n",
      "CV 4 | Epoch 580 | Loss 1.6470089554786682\n",
      "CV 4 | Epoch 590 | Loss 1.6432921707630157\n",
      "CV 4 | Epoch 600 | Loss 1.648599660396576\n",
      "CV 4 | Epoch 610 | Loss 1.6451158612966537\n",
      "CV 4 | Epoch 620 | Loss 1.6504372209310532\n",
      "CV 4 | Epoch 630 | Loss 1.6460603654384613\n",
      "CV 4 | Epoch 640 | Loss 1.6528699904680253\n",
      "CV 4 | Epoch 650 | Loss 1.6431025445461274\n",
      "CV 4 | Epoch 660 | Loss 1.6359118700027466\n",
      "CV 4 | Epoch 670 | Loss 1.6559195786714553\n",
      "CV 4 | Epoch 680 | Loss 1.646809858083725\n",
      "CV 4 | Epoch 690 | Loss 1.6447139501571655\n",
      "CV 4 | Epoch 700 | Loss 1.6398492753505707\n",
      "CV 4 | Epoch 710 | Loss 1.6496355324983596\n",
      "CV 4 | Epoch 720 | Loss 1.6404335290193557\n",
      "CV 4 | Epoch 730 | Loss 1.6434295505285264\n",
      "CV 4 | Epoch 740 | Loss 1.635424679517746\n",
      "CV 4 | Epoch 750 | Loss 1.6512595474720002\n",
      "CV 4 | Epoch 760 | Loss 1.6460358649492264\n",
      "CV 4 | Epoch 770 | Loss 1.6358251094818115\n",
      "CV 4 | Epoch 780 | Loss 1.6491155326366425\n",
      "CV 4 | Epoch 790 | Loss 1.6351531952619554\n",
      "CV 4 | Epoch 800 | Loss 1.6407931119203567\n",
      "CV 4 | Epoch 810 | Loss 1.6331407308578492\n",
      "CV 4 | Epoch 820 | Loss 1.6388270825147628\n",
      "CV 4 | Epoch 830 | Loss 1.633952271938324\n",
      "CV 4 | Epoch 840 | Loss 1.629951623082161\n",
      "CV 4 | Epoch 850 | Loss 1.6434962421655654\n",
      "CV 4 | Epoch 860 | Loss 1.6441190540790558\n",
      "CV 4 | Epoch 870 | Loss 1.631907644867897\n",
      "CV 4 | Epoch 880 | Loss 1.6344169914722442\n",
      "CV 4 | Epoch 890 | Loss 1.6346776902675628\n",
      "CV 4 | Epoch 900 | Loss 1.6350682079792023\n",
      "CV 4 | Epoch 910 | Loss 1.634462797641754\n",
      "CV 4 | Epoch 920 | Loss 1.6319775342941285\n",
      "CV 4 | Epoch 930 | Loss 1.6317463576793672\n",
      "CV 4 | Epoch 940 | Loss 1.6323842614889146\n",
      "CV 4 | Epoch 950 | Loss 1.6337696611881256\n",
      "CV 4 | Epoch 960 | Loss 1.6428026884794236\n",
      "CV 4 | Epoch 970 | Loss 1.626689577102661\n",
      "CV 4 | Epoch 980 | Loss 1.6466498166322707\n",
      "CV 4 | Epoch 990 | Loss 1.622829630970955\n",
      "CV 4 | Epoch 999 | Loss 1.629243963294559\n",
      "CV 5 | Epoch 0 | Loss 3.3418315649032593\n",
      "CV 5 | Epoch 10 | Loss 3.2091159522533417\n",
      "CV 5 | Epoch 20 | Loss 2.9720340013504027\n",
      "CV 5 | Epoch 30 | Loss 2.6860573470592497\n",
      "CV 5 | Epoch 40 | Loss 2.3212735772132875\n",
      "CV 5 | Epoch 50 | Loss 1.971767756342888\n",
      "CV 5 | Epoch 60 | Loss 1.7432969570159913\n",
      "CV 5 | Epoch 70 | Loss 1.6307125091552734\n",
      "CV 5 | Epoch 80 | Loss 1.60158152282238\n",
      "CV 5 | Epoch 90 | Loss 1.5945671200752258\n",
      "CV 5 | Epoch 100 | Loss 1.572854831814766\n",
      "CV 5 | Epoch 110 | Loss 1.55602086186409\n",
      "CV 5 | Epoch 120 | Loss 1.5586513310670853\n",
      "CV 5 | Epoch 130 | Loss 1.5424237191677093\n",
      "CV 5 | Epoch 140 | Loss 1.553124612569809\n",
      "CV 5 | Epoch 150 | Loss 1.5411977916955948\n",
      "CV 5 | Epoch 160 | Loss 1.532699966430664\n",
      "CV 5 | Epoch 170 | Loss 1.5296839654445649\n",
      "CV 5 | Epoch 180 | Loss 1.5257209300994874\n",
      "CV 5 | Epoch 190 | Loss 1.5433082938194276\n",
      "CV 5 | Epoch 200 | Loss 1.5221905946731566\n",
      "CV 5 | Epoch 210 | Loss 1.5285981893539429\n",
      "CV 5 | Epoch 220 | Loss 1.5250016748905182\n",
      "CV 5 | Epoch 230 | Loss 1.5199339538812637\n",
      "CV 5 | Epoch 240 | Loss 1.517291209101677\n",
      "CV 5 | Epoch 250 | Loss 1.5159150511026382\n",
      "CV 5 | Epoch 260 | Loss 1.5232075810432435\n",
      "CV 5 | Epoch 270 | Loss 1.527636468410492\n",
      "CV 5 | Epoch 280 | Loss 1.520671507716179\n",
      "CV 5 | Epoch 290 | Loss 1.5164086416363716\n",
      "CV 5 | Epoch 300 | Loss 1.521957316994667\n",
      "CV 5 | Epoch 310 | Loss 1.5118567287921905\n",
      "CV 5 | Epoch 320 | Loss 1.5199392080307006\n",
      "CV 5 | Epoch 330 | Loss 1.5304470926523208\n",
      "CV 5 | Epoch 340 | Loss 1.5148038208484649\n",
      "CV 5 | Epoch 350 | Loss 1.5216547846794128\n",
      "CV 5 | Epoch 360 | Loss 1.5146620124578476\n",
      "CV 5 | Epoch 370 | Loss 1.5028980046510696\n",
      "CV 5 | Epoch 380 | Loss 1.5141815572977066\n",
      "CV 5 | Epoch 390 | Loss 1.5070416003465652\n",
      "CV 5 | Epoch 400 | Loss 1.514117231965065\n",
      "CV 5 | Epoch 410 | Loss 1.5033731430768966\n",
      "CV 5 | Epoch 420 | Loss 1.5170530810952187\n",
      "CV 5 | Epoch 430 | Loss 1.5094623953104018\n",
      "CV 5 | Epoch 440 | Loss 1.508797100186348\n",
      "CV 5 | Epoch 450 | Loss 1.5146140515804292\n",
      "CV 5 | Epoch 460 | Loss 1.5130203664302826\n",
      "CV 5 | Epoch 470 | Loss 1.4967584431171417\n",
      "CV 5 | Epoch 480 | Loss 1.5144132494926452\n",
      "CV 5 | Epoch 490 | Loss 1.4998369604349135\n",
      "CV 5 | Epoch 500 | Loss 1.5060832694172859\n",
      "CV 5 | Epoch 510 | Loss 1.514230015873909\n",
      "CV 5 | Epoch 520 | Loss 1.499955451488495\n",
      "CV 5 | Epoch 530 | Loss 1.5024991124868392\n",
      "CV 5 | Epoch 540 | Loss 1.5012209445238114\n",
      "CV 5 | Epoch 550 | Loss 1.4883134752511977\n",
      "CV 5 | Epoch 560 | Loss 1.4935883164405823\n",
      "CV 5 | Epoch 570 | Loss 1.5017579972743988\n",
      "CV 5 | Epoch 580 | Loss 1.494932696223259\n",
      "CV 5 | Epoch 590 | Loss 1.4919275224208832\n",
      "CV 5 | Epoch 600 | Loss 1.498514074087143\n",
      "CV 5 | Epoch 610 | Loss 1.4863050699234008\n",
      "CV 5 | Epoch 620 | Loss 1.498788532614708\n",
      "CV 5 | Epoch 630 | Loss 1.4901150912046432\n",
      "CV 5 | Epoch 640 | Loss 1.4911874443292619\n",
      "CV 5 | Epoch 650 | Loss 1.496240770816803\n",
      "CV 5 | Epoch 660 | Loss 1.503740981221199\n",
      "CV 5 | Epoch 670 | Loss 1.4864516735076905\n",
      "CV 5 | Epoch 680 | Loss 1.4821921914815903\n",
      "CV 5 | Epoch 690 | Loss 1.4905254781246184\n",
      "CV 5 | Epoch 700 | Loss 1.4839683413505553\n",
      "CV 5 | Epoch 710 | Loss 1.4861197561025619\n",
      "CV 5 | Epoch 720 | Loss 1.4892153441905975\n",
      "CV 5 | Epoch 730 | Loss 1.4885626286268234\n",
      "CV 5 | Epoch 740 | Loss 1.486781007051468\n",
      "CV 5 | Epoch 750 | Loss 1.4884539991617203\n",
      "CV 5 | Epoch 760 | Loss 1.4847444206476212\n",
      "CV 5 | Epoch 770 | Loss 1.4790129378437995\n",
      "CV 5 | Epoch 780 | Loss 1.4846225321292876\n",
      "CV 5 | Epoch 790 | Loss 1.4894293159246446\n",
      "CV 5 | Epoch 800 | Loss 1.47770154774189\n",
      "CV 5 | Epoch 810 | Loss 1.4655252367258071\n",
      "CV 5 | Epoch 820 | Loss 1.478744775056839\n",
      "CV 5 | Epoch 830 | Loss 1.4698350965976714\n",
      "CV 5 | Epoch 840 | Loss 1.4721650421619414\n",
      "CV 5 | Epoch 850 | Loss 1.4673071086406708\n",
      "CV 5 | Epoch 860 | Loss 1.4856775194406509\n",
      "CV 5 | Epoch 870 | Loss 1.4761543273925781\n",
      "CV 5 | Epoch 880 | Loss 1.4741631895303726\n",
      "CV 5 | Epoch 890 | Loss 1.4757315963506699\n",
      "CV 5 | Epoch 900 | Loss 1.4754590541124344\n",
      "CV 5 | Epoch 910 | Loss 1.4645022362470628\n",
      "CV 5 | Epoch 920 | Loss 1.485901665687561\n",
      "CV 5 | Epoch 930 | Loss 1.4742116689682008\n",
      "CV 5 | Epoch 940 | Loss 1.4625759989023208\n",
      "CV 5 | Epoch 950 | Loss 1.4625505208969116\n",
      "CV 5 | Epoch 960 | Loss 1.4577671617269516\n",
      "CV 5 | Epoch 970 | Loss 1.4630253851413726\n",
      "CV 5 | Epoch 980 | Loss 1.4634720921516418\n",
      "CV 5 | Epoch 990 | Loss 1.479633194208145\n",
      "CV 5 | Epoch 999 | Loss 1.4696869552135468\n"
     ]
    }
   ],
   "source": [
    "th_device = th.device(device)\n",
    "\n",
    "metrics = []\n",
    "confusion_matrix = []\n",
    "syn_pred = []\n",
    "ev = Evaluator()\n",
    "\n",
    "th_device = th.device(device)\n",
    "\n",
    "syn_index = ['prev_punishments', 'prev_contributions']\n",
    "edge_index = create_fully_connected(n_player)\n",
    "\n",
    "\n",
    "def shuffle_feature(data, feature_name):\n",
    "    data = {**data}\n",
    "    data[feature_name] = data[feature_name][th.randperm(len(data[feature_name]))]\n",
    "    return data\n",
    "\n",
    "for i, (train_data, test_data) in enumerate(get_cross_validations(data, n_cross_val, fraction_training)):\n",
    "    model = AH_MODELS[model_name](default_values=default_values, **model_args).to(th_device)\n",
    "\n",
    "    train_data_ = model.encode(train_data, mask=mask_name, edge_index=edge_index)\n",
    "    if test_data is not None:\n",
    "        test_data_ = model.encode(test_data, mask=mask_name, edge_index=edge_index)\n",
    "    # syn_data_ = model.encode(syn_data, mask=None, y_encode=False, info_columns=syn_index, edge_index=edge_index)\n",
    "\n",
    "    # syn_df = using_multiindex(\n",
    "    #     Batch.from_data_list(syn_data_)['info'].detach().cpu().numpy(), ['idx', 'round_number'], syn_index)\n",
    "\n",
    "    optimizer = th.optim.Adam(model.parameters(), **optimizer_args)\n",
    "    loss_fn = th.nn.CrossEntropyLoss(reduction='none')\n",
    "    sum_loss = 0\n",
    "    n_steps = 0\n",
    "\n",
    "    for e in range(train_args['epochs']):\n",
    "        ev.set_labels(cv_split=i, epoch=e)\n",
    "        model.train()\n",
    "        for j, batch_data in enumerate(iter(DataLoader(train_data_, shuffle=True, batch_size=train_args['batch_size']))):\n",
    "            optimizer.zero_grad()\n",
    "            py = model(batch_data).flatten(end_dim=-2)\n",
    "            y_true = batch_data['y_enc'].flatten(end_dim=-2)\n",
    "            mask = batch_data['mask'].flatten()\n",
    "            loss = loss_fn(py, y_true)\n",
    "            loss = (loss * mask).sum() / mask.sum()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if train_args['clamp_grad']:\n",
    "                for param in model.parameters():\n",
    "                    param.grad.data.clamp_(-train_args['clamp_grad'], train_args['clamp_grad'])\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()\n",
    "            n_steps +=1\n",
    "        \n",
    "        last_epoch = e == (train_args['epochs'] - 1)\n",
    "\n",
    "        if (e % train_args['eval_period'] == 0) or last_epoch:\n",
    "            avg_loss = sum_loss/n_steps\n",
    "            print(f'CV {i} | Epoch {e} | Loss {avg_loss}')\n",
    "            ev.add_loss(avg_loss)\n",
    "\n",
    "            ev.eval_set(model, train_data_, calc_confusion=last_epoch, set='train')\n",
    "            if test_data is not None:\n",
    "                ev.eval_set(model, test_data_, calc_confusion=last_epoch, set='test')\n",
    "                for sf in shuffle_features:\n",
    "                    shuffled_data = shuffle_feature(test_data, sf)\n",
    "                    shuffled_data = model.encode(shuffled_data, mask=mask_name, edge_index=edge_index)\n",
    "                    ev.eval_set(model, shuffled_data, calc_confusion=False, set='test', shuffle_feature=sf)\n",
    "            sum_loss = 0\n",
    "            n_steps = 0\n",
    "    # ev.eval_syn(model, syn_data_, syn_df)\n",
    "\n",
    "ev.save(output_path, labels)\n",
    "model_path = os.path.join(output_path, 'model.pt')\n",
    "model.save(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 376.216797,
   "end_time": "2022-06-30T12:07:50.559416",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/artificial_humans/graph.ipynb",
   "output_path": "notebooks/artificial_humans/graph.ipynb",
   "parameters": {
    "data_file": "../../data/experiments/pilot_random1_player_round_slim.csv",
    "device": "cpu",
    "experiment_names": [
     "trail_rounds_2"
    ],
    "fraction_training": 1,
    "labels": {},
    "mask_name": "manager_valid",
    "model_args": {
     "add_edge_model": false,
     "add_global_model": false,
     "add_rnn": false,
     "hidden_size": 10,
     "u_encoding": [
      {
       "etype": "float",
       "name": "prev_common_good",
       "norm": 32
      },
      {
       "encoding": "numeric",
       "n_levels": 16,
       "name": "round_number"
      }
     ],
     "x_encoding": [
      {
       "encoding": "numeric",
       "n_levels": 21,
       "name": "prev_contributions"
      },
      {
       "encoding": "numeric",
       "n_levels": 31,
       "name": "prev_punishments"
      },
      {
       "etype": "bool",
       "name": "prev_valid"
      }
     ],
     "y_levels": 31,
     "y_name": "punishments"
    },
    "model_name": "graph",
    "n_cross_val": 2,
    "n_player": 4,
    "optimizer_args": {
     "lr": 0.0001,
     "weight_decay": 0.00001
    },
    "output_path": "../../data/training/dev",
    "shuffle_features": [
     "prev_punishments",
     "prev_contributions",
     "prev_common_good"
    ],
    "train_args": {
     "batch_size": 20,
     "clamp_grad": 1,
     "epochs": 100,
     "eval_period": 10
    }
   },
   "start_time": "2022-06-30T12:01:34.342619",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1198fd9370ee0cf82025240fa26724f68bfab1e3f74dbb4acdc06e7861d0dbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
