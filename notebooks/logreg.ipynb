{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "acab3ade",
   "metadata": {
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "x_encoding = [\n",
    "    {\"ordinal\": True, \"column\": \"prev_contribution\"},\n",
    "    {\"ordinal\": False, \"column\": \"prev_punishment\"},\n",
    "    {\n",
    "        \"etype\": \"interaction\",\n",
    "        \"a\": {\"ordinal\": True, \"column\": \"prev_contribution\"},\n",
    "        \"b\": {\"ordinal\": False, \"column\": \"prev_punishment\"},\n",
    "    },\n",
    "]\n",
    "y_encoding = {\"ordinal\": False, \"column\": \"contribution\"}\n",
    "model_config = {\"max_iter\": 10000, \"C\": 1.0}\n",
    "n_contributions = 21\n",
    "n_punishments = 31\n",
    "n_cross_val = 10\n",
    "fraction_training = 0.1\n",
    "data = \"../data/pilot1_player_round_slim.csv\"\n",
    "output_path = \"../data/dev\"\n",
    "labels = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "44582683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T12:51:49.618792Z",
     "iopub.status.busy": "2022-02-05T12:51:49.617907Z",
     "iopub.status.idle": "2022-02-05T12:51:50.435900Z",
     "shell.execute_reply": "2022-02-05T12:51:50.436267Z"
    },
    "papermill": {
     "duration": 0.836397,
     "end_time": "2022-02-05T12:51:50.436437",
     "exception": false,
     "start_time": "2022-02-05T12:51:49.600040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from aimanager.model.cross_validation import split_xy, get_cross_validations, get_fraction_of_groups\n",
    "from aimanager.model.encoder import int_to_ordinal, ordinal_to_int, joined_encoder, int_encode\n",
    "from aimanager.model.metrics import create_metrics, create_confusion_matrix\n",
    "from aimanager.model.synthesize_data import syn_con_pun\n",
    "from aimanager.utils.array_to_df import add_labels, using_multiindex\n",
    "from aimanager.utils.utils import make_dir\n",
    "\n",
    "output_path = os.path.join(output_path, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6659c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T12:51:50.450815Z",
     "iopub.status.busy": "2022-02-05T12:51:50.450261Z",
     "iopub.status.idle": "2022-02-05T12:51:50.478946Z",
     "shell.execute_reply": "2022-02-05T12:51:50.478495Z"
    },
    "papermill": {
     "duration": 0.038317,
     "end_time": "2022-02-05T12:51:50.479107",
     "exception": false,
     "start_time": "2022-02-05T12:51:50.440790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, x_enc, ordinal_y, n_levels):\n",
    "    y_pred = model.predict(x_enc)\n",
    "    y_pred_proba = model.predict_proba(x_enc)\n",
    "    if ordinal_y:\n",
    "        y_pred_proba = np.stack(y_pred_proba, axis=1)\n",
    "        y_pred_ordinal = y_pred\n",
    "        y_pred = ordinal_to_int(y_pred)\n",
    "    else:\n",
    "        y_pred_ordinal = int_to_ordinal(y_pred, n_levels=n_levels)\n",
    "        y_pred_proba_ = np.zeros((len(y_pred_proba), n_levels))\n",
    "        y_pred_proba_[:, model.classes_] = y_pred_proba\n",
    "        y_pred_proba = y_pred_proba_\n",
    "    return y_pred, y_pred_ordinal, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f144b88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T12:51:50.496909Z",
     "iopub.status.busy": "2022-02-05T12:51:50.496286Z",
     "iopub.status.idle": "2022-02-05T12:51:59.402627Z",
     "shell.execute_reply": "2022-02-05T12:51:59.403024Z"
    },
    "papermill": {
     "duration": 8.919725,
     "end_time": "2022-02-05T12:51:59.403222",
     "exception": false,
     "start_time": "2022-02-05T12:51:50.483497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordinal_y = y_encoding['ordinal']\n",
    "\n",
    "df = pd.read_csv(data)\n",
    "\n",
    "df['contribution'] = pd.Categorical(\n",
    "    df['contribution'], categories=np.arange(n_contributions), ordered=True\n",
    ")\n",
    "df['punishment'] = pd.Categorical(\n",
    "    df['punishment'], categories=np.arange(n_punishments), ordered=True\n",
    ")\n",
    "\n",
    "metrics = []\n",
    "confusion_matrix = []\n",
    "syn_pred = []\n",
    "\n",
    "x_df, y_sr = split_xy(df)\n",
    "for i, split in enumerate(get_cross_validations(x_df, y_sr, n_cross_val)):\n",
    "    x_train_df, y_train_sr, x_test_df, y_test_sr = split\n",
    "    x_train_df, y_train_sr = get_fraction_of_groups(x_train_df, y_train_sr, fraction_training)\n",
    "    y_test_ord = int_encode(y_test_sr, ordinal=True)\n",
    "    y_train_ord = int_encode(y_train_sr, ordinal=True)\n",
    "    y_test = int_encode(y_test_sr, ordinal=False)[:,0]\n",
    "    y_train = int_encode(y_train_sr, ordinal=False)[:,0]\n",
    "\n",
    "    y = y_train_ord if ordinal_y else y_train\n",
    "\n",
    "    x_train_enc = joined_encoder(x_train_df, x_encoding)\n",
    "    x_test_enc = joined_encoder(x_test_df, x_encoding)\n",
    "\n",
    "    if ordinal_y:\n",
    "        pipe = Pipeline([('scaler', StandardScaler()), ('log_reg', LogisticRegression(**model_config))])\n",
    "        model = MultiOutputClassifier(pipe)\n",
    "        model.fit(x_train_enc, y_train_ord)\n",
    "    else:\n",
    "        model = Pipeline([('scaler', StandardScaler()), ('log_reg', LogisticRegression(**model_config))])\n",
    "\n",
    "        y_train = pd.Categorical(\n",
    "            y_train, categories=np.arange(n_contributions), ordered=True\n",
    "        )\n",
    "\n",
    "        model.fit(x_train_enc, y_train)\n",
    "\n",
    "    # training set performance\n",
    "    y_pred, y_pred_ordinal, y_pred_proba = predict(model, x_test_enc, ordinal_y, n_levels=n_contributions)\n",
    "    metrics += create_metrics(\n",
    "        y_test, y_test_ord, y_pred, y_pred_ordinal, y_pred_proba, \n",
    "        ordinal_y=ordinal_y, n_contributions=n_contributions, set='test', cv_split=i, )\n",
    "    confusion_matrix += create_confusion_matrix(y_test, y_pred, set='test', cv_split=i)\n",
    "\n",
    "    # test set performance\n",
    "    y_pred, y_pred_ordinal, y_pred_proba = predict(model, x_train_enc, ordinal_y, n_levels=n_contributions)\n",
    "    metrics += create_metrics(\n",
    "        y_train, y_train_ord, y_pred, y_pred_ordinal, y_pred_proba, \n",
    "        ordinal_y=ordinal_y, n_contributions=n_contributions, set='train', cv_split=i)\n",
    "    confusion_matrix += create_confusion_matrix(y_train, y_pred, set='train', cv_split=i)\n",
    "\n",
    "    # eval synthesized data\n",
    "    x_syn_df = syn_con_pun(n_contributions, n_punishments)\n",
    "    x_syn = joined_encoder(x_syn_df, x_encoding)\n",
    "    y_pred, y_pred_ordinal, y_pred_proba = predict(model, x_syn, ordinal_y, n_levels=n_contributions)\n",
    "    if ordinal_y:\n",
    "        y_pred_proba = np.concatenate([np.ones_like(y_pred_proba[:,[0],1]), y_pred_proba[:,:,1]], axis=1)\n",
    "    proba_df = using_multiindex(y_pred_proba, ['sample_idx', 'contribution']).rename(columns={'value': 'proba'})\n",
    "    x_syn_df['contribution_pred'] = y_pred\n",
    "    proba_df =  x_syn_df.merge(proba_df)\n",
    "    proba_df['predicted'] = proba_df['contribution_pred'] == proba_df['contribution']\n",
    "    proba_df = proba_df.drop(columns = ['contribution_pred'])\n",
    "    proba_df = add_labels(proba_df, {'set': 'train', 'cv_split': i})\n",
    "    syn_pred += proba_df.to_dict('records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577d496c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-05T12:51:59.416705Z",
     "iopub.status.busy": "2022-02-05T12:51:59.416056Z",
     "iopub.status.idle": "2022-02-05T12:51:59.707187Z",
     "shell.execute_reply": "2022-02-05T12:51:59.707548Z"
    },
    "papermill": {
     "duration": 0.300417,
     "end_time": "2022-02-05T12:51:59.707707",
     "exception": false,
     "start_time": "2022-02-05T12:51:59.407290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_dir(output_path)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "metrics_df = add_labels(metrics_df, labels)\n",
    "metrics_df.to_parquet(os.path.join(output_path, 'metrics.parquet'))\n",
    "\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix)\n",
    "confusion_matrix_df = add_labels(confusion_matrix_df, labels)\n",
    "confusion_matrix_df.to_parquet(os.path.join(output_path, 'confusion_matrix.parquet'))\n",
    "\n",
    "syn_pred_df = pd.DataFrame(syn_pred)\n",
    "syn_pred_df = add_labels(syn_pred_df, labels)\n",
    "syn_pred_df.to_parquet(os.path.join(output_path, 'synthetic_predicitions.parquet'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1198fd9370ee0cf82025240fa26724f68bfab1e3f74dbb4acdc06e7861d0dbe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.770634,
   "end_time": "2022-02-05T12:52:00.032430",
   "environment_variables": {},
   "exception": null,
   "input_path": "logreg.ipynb",
   "output_path": "logreg.ipynb",
   "parameters": {
    "data": "../data/pilot1_player_round_slim.csv",
    "fraction_training": 0.1,
    "labels": {},
    "model_config": {
     "C": 1,
     "max_iter": 10000
    },
    "n_contributions": 21,
    "n_cross_val": 10,
    "n_punishments": 31,
    "output_path": "../data/dev",
    "x_encoding": [
     {
      "column": "prev_contribution",
      "ordinal": true
     },
     {
      "column": "prev_punishment",
      "ordinal": false
     },
     {
      "a": {
       "column": "prev_contribution",
       "ordinal": true
      },
      "b": {
       "column": "prev_punishment",
       "ordinal": false
      },
      "etype": "interaction"
     }
    ],
    "y_encoding": {
     "column": "contribution",
     "ordinal": false
    }
   },
   "start_time": "2022-02-05T12:51:48.261796",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
