{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938bee81",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [4]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02b40f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T12:17:35.460875Z",
     "iopub.status.busy": "2023-03-16T12:17:35.460517Z",
     "iopub.status.idle": "2023-03-16T12:17:35.469236Z",
     "shell.execute_reply": "2023-03-16T12:17:35.468292Z"
    },
    "papermill": {
     "duration": 0.017038,
     "end_time": "2023-03-16T12:17:35.471622",
     "exception": false,
     "start_time": "2023-03-16T12:17:35.454584",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "run = \"02_3_valid\"\n",
    "base_folder = \"artificial_humans\"\n",
    "target = \"valid\"\n",
    "selection = {\"rnn\": True}\n",
    "order = [\"True\", \"False\"]\n",
    "pairs = [[\"True\", \"False\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b246b326",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T12:17:35.510969Z",
     "iopub.status.busy": "2023-03-16T12:17:35.510638Z",
     "iopub.status.idle": "2023-03-16T12:17:38.190111Z",
     "shell.execute_reply": "2023-03-16T12:17:38.189645Z"
    },
    "papermill": {
     "duration": 2.685143,
     "end_time": "2023-03-16T12:17:38.191843",
     "exception": false,
     "start_time": "2023-03-16T12:17:35.506700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/levinbrinkmann/repros/algorithmic-institutions/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch as th\n",
    "import matplotlib.pyplot as plt\n",
    "from aimanager.utils.utils import make_dir\n",
    "from aimanager.utils.merge import merge_files_by_name\n",
    "\n",
    "sns.set(rc={'axes.facecolor':'white', 'figure.facecolor':'white'})\n",
    "\n",
    "data_folder = os.path.join('../../data', base_folder, run)\n",
    "plot_folder = f'plots/{base_folder}_{run}'\n",
    "\n",
    "make_dir(plot_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "106538af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T12:17:38.197445Z",
     "iopub.status.busy": "2023-03-16T12:17:38.197096Z",
     "iopub.status.idle": "2023-03-16T12:17:38.228113Z",
     "shell.execute_reply": "2023-03-16T12:17:38.227496Z"
    },
    "papermill": {
     "duration": 0.035916,
     "end_time": "2023-03-16T12:17:38.230047",
     "exception": false,
     "start_time": "2023-03-16T12:17:38.194131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _plot_heatmap(data, x, y, values, normalise=True):\n",
    "    dfg = data.groupby([x,y])[values].sum()\n",
    "    dfg = dfg.reset_index()\n",
    "    if normalise:\n",
    "        dfg[values] = dfg[values] / dfg.groupby([x])[values].transform('sum')\n",
    "    cm = dfg.pivot_table(index=x, columns=y, values=values)\n",
    "    cm = cm.sort_index(ascending=False)\n",
    "    sns.heatmap(cm)\n",
    "\n",
    "def merge_data(data_folder, metric_name):\n",
    "    folder = os.path.join(data_folder, metric_name)\n",
    "    dfs = [pd.read_parquet(os.path.join(folder, file)) for file in os.listdir(folder)]\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e318dfb",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b21dc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-16T12:17:38.236326Z",
     "iopub.status.busy": "2023-03-16T12:17:38.236017Z",
     "iopub.status.idle": "2023-03-16T12:17:38.730282Z",
     "shell.execute_reply": "2023-03-16T12:17:38.729261Z"
    },
    "papermill": {
     "duration": 0.49912,
     "end_time": "2023-03-16T12:17:38.731653",
     "exception": true,
     "start_time": "2023-03-16T12:17:38.232533",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/artificial_humans/02_3_valid/metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetrics\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcv_split\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m      3\u001b[0m confusion_matrix_df \u001b[38;5;241m=\u001b[39m merge_data(data_folder, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfusion_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mmerge_data\u001b[0;34m(data_folder, metric_name)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_data\u001b[39m(data_folder, metric_name):\n\u001b[1;32m     11\u001b[0m     folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_folder, metric_name)\n\u001b[0;32m---> 12\u001b[0m     dfs \u001b[38;5;241m=\u001b[39m [pd\u001b[38;5;241m.\u001b[39mread_parquet(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder, file)) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m     13\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/artificial_humans/02_3_valid/metrics'"
     ]
    }
   ],
   "source": [
    "metrics_df = merge_data(data_folder, 'metrics')\n",
    "print(metrics_df['cv_split'].unique())\n",
    "confusion_matrix_df = merge_data(data_folder, 'confusion_matrix')\n",
    "metrics_df['shuffle_feature'] = metrics_df['shuffle_feature'].fillna('none')\n",
    "labels = list(set(metrics_df.columns) - set(['job_id', 'name', 'value', 'cv_split', 'epoch', 'set', 'strategy', 'shuffle_feature']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622490f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = metrics_df.copy()\n",
    "\n",
    "\n",
    "focus = [*labels, 'set']\n",
    "\n",
    "sel = {\n",
    "    'name': 'log_loss',\n",
    "    'shuffle_feature': 'none',\n",
    "}\n",
    "\n",
    "w = pd.concat(\n",
    "    (df[k].isin(v) if isinstance(v, list) else df[k] == v\n",
    "    for k,v in sel.items()\n",
    "    if (k not in focus) or isinstance(v, list)), axis=1\n",
    ").all(1)\n",
    "\n",
    "df = df[w]\n",
    "\n",
    "fg = sns.relplot(\n",
    "    data=df, \n",
    "    x='epoch', y='value',\n",
    "    hue=focus[0] if len(focus) >= 1 else None, \n",
    "    style=focus[1] if len(focus) >= 2 else None,\n",
    "    col=focus[2] if len(focus) >= 3 else None, \n",
    "    row=focus[3] if len(focus) >= 4 else None, \n",
    "    kind='line', ci=None)\n",
    "\n",
    "fg.set(ylabel='cross entropy')\n",
    "\n",
    "fg.savefig(os.path.join(plot_folder, 'learning_curve_model.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7930b6f2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "\n",
    "df = metrics_df.copy()\n",
    "\n",
    "w = (\n",
    "    (df['name'] == 'log_loss') &\n",
    "    (df['set'] == 'test') &\n",
    "    (df['shuffle_feature'] == 'none')\n",
    ")\n",
    "df = df[w].copy()\n",
    "w_max = (df['epoch'] > (0.8 * df['epoch'].max()))\n",
    "df = df[w_max].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d0cf02",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = metrics_df.copy()\n",
    "\n",
    "focus = labels\n",
    "\n",
    "w = (\n",
    "    (df['name'] == 'log_loss') &\n",
    "    (df['set'] == 'test') &\n",
    "    (df['shuffle_feature'] == 'none')\n",
    ")\n",
    "df = df[w].copy()\n",
    "w_max = (df['epoch'] > (0.8 * df['epoch'].max()))\n",
    "df = df[w_max].copy()\n",
    "\n",
    "\n",
    "fg = sns.catplot(\n",
    "    data=df, \n",
    "    y='value',\n",
    "    x=focus[0] if len(focus) >= 1 else None, \n",
    "    hue=focus[1] if len(focus) >= 2 else None,\n",
    "    col=focus[2] if len(focus) >= 3 else None, \n",
    "    row=focus[3] if len(focus) >= 4 else None, \n",
    "    kind='box')\n",
    "\n",
    "fg.set(ylabel='cross entropy')\n",
    "\n",
    "fg.savefig(os.path.join(plot_folder, 'cross_entropy_box.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b1587b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = metrics_df.copy()\n",
    "\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "w = (\n",
    "    (df['name'] == 'log_loss') &\n",
    "    (df['set'] == 'test') &\n",
    "    (df['shuffle_feature'] == 'none')\n",
    ")\n",
    "df = df[w].copy()\n",
    "w_max = (df['epoch'] > (0.8 * df['epoch'].max()))\n",
    "df = df[w_max].copy()\n",
    "\n",
    "dfm = df.groupby([*labels, 'cv_split'])['value'].mean().reset_index()\n",
    "dfm['mean_value'] = df.groupby(labels)['value'].transform('mean')\n",
    "\n",
    "dfm[labels[0]] = dfm[labels[0]].astype(str)\n",
    "\n",
    "\n",
    "ax = sns.barplot(\n",
    "    data=dfm, \n",
    "    order=order,\n",
    "    y='value',\n",
    "    x=labels[0],\n",
    "    errorbar=None\n",
    ")\n",
    "if pairs is not None:\n",
    "    annotator = Annotator(ax, pairs, data=dfm, x=labels[0], y='value', order=order)\n",
    "    annotator.configure(test=test, text_format='simple', loc='inside')\n",
    "    annotator.apply_and_annotate()\n",
    "\n",
    "plt.savefig(os.path.join(plot_folder, 'model_comparision.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a2211",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = metrics_df.copy()\n",
    "\n",
    "w = (\n",
    "    (df['name'] == 'log_loss') &\n",
    "    (df['set'] == 'test') \n",
    ")\n",
    "df = df[w].copy()\n",
    "\n",
    "df_p = df.pivot(index=[*labels, 'name', 'cv_split', 'set', 'epoch'], columns='shuffle_feature', values='value')\n",
    "df_p = df_p.sub(df_p['none'], axis=0)\n",
    "df_p = df_p.stack()\n",
    "df_p.name = 'value'\n",
    "df_p = df_p.reset_index()\n",
    "df_p = df_p[df_p['shuffle_feature'].isin(['prev_contributions', 'prev_punishments', 'prev_valid'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec284eef",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "focus = ['shuffle_feature']\n",
    "\n",
    "sel = {\n",
    "    'name': 'log_loss',\n",
    "    'set': 'test',\n",
    "    **selection\n",
    "}\n",
    "\n",
    "w = pd.concat(\n",
    "    (df_p[k].isin(v) if isinstance(v, list) else df_p[k] == v\n",
    "    for k,v in sel.items()\n",
    "    if (k not in focus) or isinstance(v, list)), axis=1\n",
    ").all(1)\n",
    "\n",
    "\n",
    "dfs = df_p[w].copy()\n",
    "\n",
    "ax = sns.barplot(\n",
    "    data=df_p, \n",
    "    x='shuffle_feature', y='value',\n",
    "    errorbar=None\n",
    ")\n",
    "\n",
    "ax.set(ylabel='loss in cross entropy', xlabel='shuffled feature')\n",
    "\n",
    "plt.savefig(os.path.join(plot_folder, 'shuffle_feature_importance.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec18f7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = confusion_matrix_df.copy()\n",
    "\n",
    "sel = {\n",
    "    'round_number': 0,\n",
    "    'valid': True,\n",
    "    'set': 'test',\n",
    "    **selection\n",
    "}\n",
    "\n",
    "w = pd.concat(\n",
    "    (df[k].isin(v) if isinstance(v, list) else df[k] == v\n",
    "    for k,v in sel.items()\n",
    "    if (k not in focus) or isinstance(v, list)), axis=1\n",
    ").all(1)\n",
    "\n",
    "\n",
    "df = df[w]\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "dfc['probability'] = df[f'pred_{target}'] == df[f'true_{target}']\n",
    "dfc['method'] = 'empirical'\n",
    "df['probability'] = df['proba']\n",
    "df['method'] = 'modeled'\n",
    "\n",
    "df = pd.concat([dfc, df]).reset_index()\n",
    "\n",
    "fg = sns.catplot(\n",
    "    data=df, \n",
    "    x=f'pred_{target}', \n",
    "    y='probability',\n",
    "    hue='method',\n",
    "    height=5, kind='bar')\n",
    "\n",
    "fg.savefig(os.path.join(plot_folder, 'action_histogram.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0fdce0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = confusion_matrix_df.copy()\n",
    "\n",
    "sel = {\n",
    "    'valid': True,\n",
    "    'set': 'test',\n",
    "    **selection\n",
    "}\n",
    "\n",
    "w = pd.concat(\n",
    "    (df[k].isin(v) if isinstance(v, list) else df[k] == v\n",
    "    for k,v in sel.items()\n",
    "    if (k not in focus) or isinstance(v, list)), axis=1\n",
    ").all(1)\n",
    "\n",
    "df = df[w]\n",
    "\n",
    "dfc = df.copy()\n",
    "\n",
    "\n",
    "plot_heatmap = lambda data, color: _plot_heatmap(\n",
    "    data, x=f'true_{target}',y=f'pred_{target}', values='proba')\n",
    "\n",
    "fg = sns.FacetGrid(\n",
    "    dfc, height=5)\n",
    "fg.map_dataframe(plot_heatmap)\n",
    "\n",
    "\n",
    "fg.savefig(os.path.join(plot_folder, 'confusion_matrix.jpg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.312013,
   "end_time": "2023-03-16T12:17:39.354301",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/evalutation/predictive_models.ipynb",
   "output_path": "notebooks/evalutation/predictive_models/predictive_models.ahc_02_valid.ipynb",
   "parameters": {
    "base_folder": "artificial_humans",
    "order": [
     "True",
     "False"
    ],
    "pairs": [
     [
      "True",
      "False"
     ]
    ],
    "run": "02_3_valid",
    "selection": {
     "rnn": true
    },
    "target": "valid"
   },
   "start_time": "2023-03-16T12:17:34.042288",
   "version": "2.3.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "83484b78e3eced0c1ebbaf37dd8049c2f9102f6dcade2a60a08a368fc0daac5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}